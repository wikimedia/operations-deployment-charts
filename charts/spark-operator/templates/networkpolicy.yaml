{{/*
egress rule template allowing access to kubernetesMasters.cidrs
*/}}
{{- define "spark-operator.k8s-api-rule" }}
- action: Allow
  destination:
    services:
      name: kubernetes
      namespace: default
{{- end }}

{{- if .Values.networkpolicy.egress.enabled }}
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: {{ template "base.name.release" . }}
  labels:
    app: {{ template "base.name.chart" . }}
    chart: {{ template "base.name.chartid" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
spec:
  podSelector:
    matchLabels:
      app: {{ template "base.name.chart" . }}
      release: {{ .Release.Name }}
  policyTypes:
    - Egress
  egress:
    {{- include "base.networkpolicy.egress-basic" .Values }}
    {{- include "base.networkpolicy.egress.kafka" . | indent 4 }}
{{- end }}
# The following two NetworkPolicy objects are only required in production.
{{- if eq .Values.service.deployment "production" }}
# Allow spark-driver pods in the watched namespace to query the K8s API. 
---
apiVersion: crd.projectcalico.org/v1
kind: NetworkPolicy
metadata:
  name: spark-driver-k8s-api
  namespace: {{ .Values.watchNamespace }}
  labels:
    app: {{ template "base.name.chart" . }}
    chart: {{ template "base.name.chartid" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
spec:
  selector: 'spark-role == "driver"'
  types:
    - Egress
  egress:
    {{- include "spark-operator.k8s-api-rule" $ | nindent 4 }}
---
apiVersion: crd.projectcalico.org/v1
kind: NetworkPolicy
metadata:
  name: spark-operator-k8s-api
  labels:
    app: {{ template "base.name.chart" . }}
    chart: {{ template "base.name.chartid" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
spec:
  selector: all()
  types:
    - Egress
  egress:
    {{- include "spark-operator.k8s-api-rule" $ | nindent 4 }}
{{- if .Values.webhook.enable }}
# Allow K8S API to call the spark operator mutating webhook
---
apiVersion: crd.projectcalico.org/v1
kind: NetworkPolicy
metadata:
  name: spark-operator-mutating-webhook-k8s-api
  labels:
    app: {{ template "base.name.chart" . }}
    chart: {{ template "base.name.chartid" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
spec:
  selector: 'app == "spark-operator"'
  types:
    - Ingress
  ingress:
  - action: Allow
    destination:
      services:
        name: {{ template "base.name.release" . }}
        namespace: {{ .Release.Namespace }}
    protocol: TCP
    source:
        services:
          name: kubernetes
          namespace: default
{{- end }}
# Allow communication between driver and executor pods.
---
apiVersion: crd.projectcalico.org/v1
kind: NetworkPolicy
metadata:
  name: spark-executor-to-driver
  namespace: {{ .Values.watchNamespace }}
  labels:
    app: {{ template "base.name.chart" . }}
    chart: {{ template "base.name.chartid" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
spec:
  selector: 'spark-role == "driver"'
  ingress:
    - action: Allow
      protocol: TCP
      source:
        selector: 'spark-role == "executor"'
      destination:
        ports:
          - 12000 # spark.driver.port
          - 13000 # spark.driver.blockManager.port
# Allow communication from spark pods to HDFS and Hive.
---
apiVersion: crd.projectcalico.org/v1
kind: NetworkPolicy
metadata:
  name: spark-to-hdfs-hive
  namespace: {{ .Values.watchNamespace }}
  labels:
    app: {{ template "base.name.chart" . }}
    chart: {{ template "base.name.chartid" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
spec:
  selector: 'spark-role == "driver" || spark-role == "executor"'
  types:
    - Egress
  egress:
    - action: Allow
      protocol: TCP
      destination:
        nets:
          # eqiad analytics subnets
          - "10.64.138.0/24"
          - "10.64.139.0/24"
          - "10.64.140.0/24"
          - "10.64.142.0/24"
          - "10.64.143.0/24"
          - "10.64.144.0/24"
          - "10.64.21.0/24"
          - "10.64.36.0/24"
          - "10.64.5.0/24"
          - "10.64.53.0/24"
        ports:
          - 8020 # HDFS Namenode RPC
          - 50010 # HDFS Datanode RPC
          - 9083 # Hive metastore thrift
          - 10000 # Hive server2 thrift
{{- end }}
