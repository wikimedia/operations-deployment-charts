# This manifest installs the calico-node container on
# each worker node in a Kubernetes cluster.
kind: DaemonSet
apiVersion: apps/v1
metadata:
  name: calico-node
  namespace: kube-system
  labels:
    k8s-app: calico-node
    {{- include "calico.labels" . | nindent 4 }}
spec:
  selector:
    matchLabels:
      k8s-app: calico-node
      {{- include "calico.selectorLabels" . | nindent 6 }}
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  template:
    metadata:
      labels:
        k8s-app: calico-node
        {{- include "calico.labels" . | nindent 8 }}
    spec:
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      hostNetwork: true
      nodeSelector:
        kubernetes.io/os: linux
      tolerations:
        # Make sure calico-node gets scheduled on all nodes.
        - effect: NoSchedule
          operator: Exists
        # Mark the pod as a critical add-on for rescheduling.
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoExecute
          operator: Exists
      serviceAccountName: calico-node
      securityContext:
        seccompProfile:
          type: RuntimeDefault
      # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a "force
      # deletion": https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.
      terminationGracePeriodSeconds: 0
      priorityClassName: system-node-critical
      {{- if or .Values.bpf .Values.cni.install }}
      initContainers:
        {{- if .Values.bpf }}
        # This init container mounts the necessary filesystems needed by the BPF data plane
        # i.e. bpf at /sys/fs/bpf and cgroup2 at /run/calico/cgroup. Calico-node initialization is executed
        # in best effort fashion, i.e. no failure for errors, to not disrupt pod creation in iptables mode.
        - name: "mount-bpffs"
          image: "{{ .Values.image.repository }}/{{ .Values.calicoNode.imageName }}:v{{ .Values.image.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          command: ["calico-node", "-init", "-best-effort"]
          volumeMounts:
            - mountPath: /sys/fs
              name: sys-fs
              # Bidirectional is required to ensure that the new mount we make at /sys/fs/bpf propagates to the host
              # so that it outlives the init container.
              mountPropagation: Bidirectional
            - mountPath: /var/run/calico
              name: var-run-calico
              # Bidirectional is required to ensure that the new mount we make at /run/calico/cgroup propagates to the host
              # so that it outlives the init container.
              mountPropagation: Bidirectional
            # Mount /proc/ from host which usually is an init program at /nodeproc. It's needed by mountns binary,
            # executed by calico-node, to mount root cgroup2 fs at /run/calico/cgroup to attach CTLB programs correctly.
            - mountPath: /nodeproc
              name: nodeproc
              readOnly: true
          securityContext:
            privileged: true
        {{- end }}
        {{- if .Values.cni.install }}
        # This container installs the CNI binaries
        # and CNI network config file on each node.
        - name: install-cni
          image: docker.io/calico/cni:v{{ .Chart.AppVersion }}
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          command: ["/opt/cni/bin/install"]
          envFrom:
          - configMapRef:
              # Allow KUBERNETES_SERVICE_HOST and KUBERNETES_SERVICE_PORT to be overridden for eBPF mode.
              name: kubernetes-services-endpoint
              optional: true
          env:
            {{- if .Values.bpf }}
            # Overrides for kubernetes API server host/port. Needed in BPF mode.
            - name: KUBERNETES_SERVICE_HOST
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: kubernetes_service_host
            - name: KUBERNETES_SERVICE_PORT
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: kubernetes_service_port
            {{- end }}
            # Name of the CNI config file to create.
            - name: CNI_CONF_NAME
              value: "10-calico.conflist"
            # The CNI network config to install on each node.
            - name: CNI_NETWORK_CONFIG
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: cni_network_config
            # Set the hostname based on the k8s node name.
            - name: KUBERNETES_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            {{- if .Values.cni.install }}
            # CNI MTU Config variable
            - name: CNI_MTU
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: veth_mtu
            {{- end }}
            # Prevents the container from sleeping forever.
            - name: SLEEP
              value: "false"
            {{- if .Values.cni.env }}
              {{ toYaml .Values.cni.env | nindent 12 }}
            {{- end }}
          volumeMounts:
            - mountPath: /host/opt/cni/bin
              name: cni-bin-dir
            - mountPath: /host/etc/cni/net.d
              name: cni-net-dir
          securityContext:
            privileged: true
        {{- end }}

      {{- end }} {{/* if or .Values.bpf .Values.cni.install */}}
      containers:
        # Runs calico-node container on each Kubernetes node. This
        # container programs network policy and routes on each
        # host.
        - name: calico-node
          image: "{{ .Values.image.repository }}/{{ .Values.calicoNode.imageName }}:v{{ .Values.image.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          env:
          {{- if .Values.bpf }}
            # Overrides for kubernetes API server host/port. Needed in BPF mode.
            - name: KUBERNETES_SERVICE_HOST
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: kubernetes_service_host
            - name: KUBERNETES_SERVICE_PORT
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: kubernetes_service_port
            # Actually enable BPF mode.
            - name: FELIX_BPFENABLED
              value: "true"
          {{- end }}
            # Don't try to manage the CNI's kubeconfig/token (puppet does that)
            - name: CALICO_MANAGE_CNI
              value: "{{ .Values.cni.install }}"
            # Use Kubernetes API as the backing datastore.
            - name: DATASTORE_TYPE
              value: "kubernetes"
            # Typha support: controlled by the ConfigMap.
            - name: FELIX_TYPHAK8SSERVICENAME
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: typha_service_name
            # Wait for the datastore.
            - name: WAIT_FOR_DATASTORE
              value: "true"
            # Set based on the k8s node name.
            - name: NODENAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            # Choose the backend to use.
            - name: CALICO_NETWORKING_BACKEND
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: calico_backend
            # Cluster type to identify the deployment type
            - name: CLUSTER_TYPE
              value: "k8s,bgp"
            # Auto-detect the BGP IP address.
            - name: IP
              value: "autodetect"
            # Auto-detect the BGP IPv6 address.
            - name: IP6
              {{- if .Values.IPv6Support }}
              value: "autodetect"
              {{- else }}
              value: "none"
              {{- end }}
            # Prevent Calico from creating a default pool if one does not exist.
            # This means we don't need all the CALICO_IPV(4|6)_ variables the upstream chart uses
            - name: NO_DEFAULT_POOLS
              value: "true"
            # Disable file logging so `kubectl logs` works.
            - name: CALICO_DISABLE_FILE_LOGGING
              value: "true"
            # Set Felix endpoint to host default action to ACCEPT.
            - name: FELIX_DEFAULTENDPOINTTOHOSTACTION
              value: "ACCEPT"
            - name: FELIX_IPV6SUPPORT
              value: "{{ .Values.IPv6Support }}"
            - name: FELIX_HEALTHENABLED
              value: "true"
            # Since calico-node/Felix is host-networked, this opens a port on the host.
            # Extra scrape targets are in place in prometheus.
            - name: FELIX_PROMETHEUSMETRICSENABLED
              value: "true"
            - name: FELIX_PROMETHEUSMETRICSPORT
              value: "9091"
            # Have felix set the src parameter in routes it creates to so that
            # source address selection is forced. That way liveness/readiness
            # probes will originate from the node's IP
            - name: FELIX_DEVICEROUTESOURCEADDRESS
              valueFrom:
                fieldRef:
                  # Note that we can use status.podIP or status.hostIP here
                  # interchangeable. Since calico-node is a Daemonset it
                  # doesn't matter, but we use hostIP to be explicit
                  fieldPath: status.hostIP
            # Location of the CA bundle Felix uses to authenticate Typha; volume mount
            #- name: FELIX_TYPHACAFILE
            #  value: /calico-typha-ca/typhaca.crt
            # Common name on the Typha certificate; used to verify we are talking to an authentic typha
            #- name: FELIX_TYPHACN
            #  value: calico-typha
            # Location of the client certificate for connecting to Typha; volume mount
            #- name: FELIX_TYPHACERTFILE
            #  value: /calico-node-certs/calico-node.crt
            # Location of the client certificate key for connecting to Typha; volume mount
            #- name: FELIX_TYPHAKEYFILE
            #  value: /calico-node-certs/calico-node.key
          securityContext:
            privileged: true
          lifecycle:
            preStop:
              exec:
                command:
                - /bin/calico-node
                - -shutdown
          livenessProbe:
            exec:
              command:
              - /bin/calico-node
              - -felix-live
              - -bird-live
            periodSeconds: 10
            initialDelaySeconds: 10
            failureThreshold: 6
            timeoutSeconds: 10
          readinessProbe:
            exec:
              command:
              - /bin/calico-node
              - -felix-ready
              - -bird-ready
            periodSeconds: 10
            timeoutSeconds: 10
          resources:
            {{- toYaml .Values.calicoNode.resources | nindent 12 }}
          volumeMounts:
          {{- if .Values.cni.install }}
            - mountPath: /host/etc/cni/net.d
              name: cni-net-dir
              readOnly: false
          {{- end }}
            - mountPath: /lib/modules
              name: lib-modules
              readOnly: true
            - mountPath: /run/xtables.lock
              name: xtables-lock
              readOnly: false
            - mountPath: /var/run/calico
              name: var-run-calico
              readOnly: false
            - mountPath: /var/lib/calico
              name: var-lib-calico
              readOnly: false
            - name: policysync
              mountPath: /var/run/nodeagent
            {{- if .Values.bpf }}
            # For eBPF mode, we need to be able to mount the BPF filesystem at /sys/fs/bpf so we mount in the
            # parent directory.
            - name: bpffs
              mountPath: /sys/fs/bpf
            {{- end }}
            # calico-node logs to /var/log/calico in addition to stdout
            # as we collect stdout anyways, avoid the extra writes to overlayfs by sending logs to emptyDir
            - mountPath: /var/log/calico
              name: var-log-calico
              readOnly: false
      volumes:
        # Used by calico-node.
        - name: lib-modules
          hostPath:
            path: /lib/modules
        - name: var-run-calico
          hostPath:
            path: /var/run/calico
            type: DirectoryOrCreate
        - name: var-lib-calico
          hostPath:
            path: /var/lib/calico
            type: DirectoryOrCreate
        - name: xtables-lock
          hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
        {{- if .Values.bpf }}
        - name: sys-fs
          hostPath:
            path: /sys/fs/
            type: DirectoryOrCreate
        - name: bpffs
          hostPath:
            path: /sys/fs/bpf
            type: Directory
        # mount /proc at /nodeproc to be used by mount-bpffs initContainer to mount root cgroup2 fs.
        - name: nodeproc
          hostPath:
            path: /proc
        {{- end }}
        {{- if .Values.cni.install }}
        # Used to install CNI.
        - name: cni-bin-dir
          hostPath:
            path: /opt/cni/bin
            type: DirectoryOrCreate
        - name: cni-net-dir
          hostPath:
            path: /etc/cni/net.d
        # Used to access CNI logs.
        - name: cni-log-dir
          hostPath:
            path: /var/log/calico/cni
        {{- end }}
        # Used to create per-pod Unix Domain Sockets
        - name: policysync
          hostPath:
            type: DirectoryOrCreate
            path: /var/run/nodeagent
        - name: var-log-calico
          emptyDir: {}
