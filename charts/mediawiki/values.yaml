# Default values for MediaWiki.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
helm_scaffold_version: 0.2 # This can be useful when backporting fixes.
docker:
  registry: docker-registry.wikimedia.org
  pull_policy: IfNotPresent
resources:
  replicas: 1
terminationGracePeriodSeconds: 10
strategy:
  type: RollingUpdate
  rollingUpdate:
    maxUnavailable: 3%
    maxSurge: 3%
main_app:
  image: placeholder-for-mediawiki-image-name
  version: latest # we use latest everywhere in the defaults.
  port: 8080 # This is the same as php.httpd.port
  # Limits that make sense for a local dev:
  # 1 - 4 Gb of RAM is the minimum for having some APC + opcache for all
  #     the code + 4xncpu workers.
  # For production (i.e. multiversion) installs, you will need:
  # - 400 Mb for opcache (~ 50 Mb for strings)
  # - 1 GB for apcu (maybe something more for appservers)
  # - 500 Mb per worker
  # - 500mi CPU per worker + 500mi for the master process
  # Following removed and calculated in lamp deployment based on php workers number
  requests:
    # Set to true to ignore the cpu/memory requests and let the chart compute them
    # See php.cpu_per_worker and php.memory_per_worker for documentation
    auto_compute: false
    cpu: 1000m
    memory: 3500Mi # This allows up to 5 workers
  limits:
    # Set to true to enforce cpu/memory limits, if this is false no limits will be set
    enforce: true
    auto_compute: false
    cpu: 2000m
    memory: 4000Mi
  # Needs to finish after envoy, so it's set to mesh.prestop_sleep + 1
  prestop_sleep: 8

monitoring:
  # If enabled is true, monitoring annotations will be added to the deployment.
  # MediaWiki's data can be scraped using named ports only so it will by default
  # assume named_ports is set to true even if not indicated here.
  enabled: false
  statsd: ~
  # If you want to enable prometheus-statsd-exporter in the pod, add the following:
  # statsd:
  # # Needs to finish after envoy, so it's set to mesh.prestop_sleep + 1
  #   prestop_sleep: 8
  #   requests:
  #     memory: 100M
  #     cpu: 100m
  #   limits:
  #     memory: 200M
  #     cpu: 200m
  #   # Add the configuration inline
  #   config: |-
  #     ...

service:
  # Select deployment: "none" to indicate that no k8s service should be
  # deployed for this release. This is useful together with the route_via
  # top-level value to instead serve a portion of traffic via the service
  # associated with another release.
  deployment: minikube # valid values are "production" "minikube" and "none"
  expose_http: false # set this to true if you want to expose both the https and http endpoint
  port:
    name: http # a unique name of lowercase alphanumeric characters or "-", starting and ending with alphanumeric, max length 63
    # protocol: TCP # TCP is the default protocol
    targetPort: 8080 # the number or name of the exposed port on the container
    port: 8080 # the number of the port desired to be exposed to the cluster
    nodePort: null # you need to define this if "production" is used. In minikube environments let it autoallocate
config:
  public: {} # Add here all the keys that can be publicly available as a ConfigMap
  private: {} # Add here all the keys that should be private but still available as env variables

mesh:
  enabled: false # Switch to true in production
  # image_version: 1.18.3-2-s2 # image_version is defined globally by SRE. May be overridden here, though.
  public_port: 4444 # the port where TLS will be exposed
  upstream_timeout: "180.0s"
  # To be defined in a private space
  certs:
    cert: "snakeoil"
    key: "snakeoil"
  # Add here, via our "secret" system, the cert/key pairs
  #   cert: "your cert here"
  #   key: "your key here"
  # Enable telemetry
  telemetry:
    enabled: true
    port: 9361
  # Inject the Ip address of the connecting server, as x-client-ip, to be consumed
  # by mod_remoteip upstream, so that we never end up with REMOTE_ADDR equal to localhost,
  # which triggers a soft block in mediawiki.
  # We chose to append the header because mod_remoteip always uses the first it encounters in the request,
  # so if there is an original one it is preserved. This is more important for access logs than
  # for any functionality. See T297613
  request_headers_to_add:
    - header: "x-client-ip"
      value: "%DOWNSTREAM_REMOTE_ADDRESS_WITHOUT_PORT%"
      append: true
  admin:
    port: "1666"
    drain_time_s: "600"
    drain_strategy: "gradual"
  # Picked by using ~2x biggest p99 spikes for POST to appservers
  # All other containers in the pod need to finish after, so remember to bump the other
  # prestop_sleep variables if this is changed.
  prestop_sleep: 7
  # Following setting sets up number of workers for envoy.
  # Defaults to envoy default behaviour of number of hardware CPUs
  #concurrency: "12"
  resources:
    requests:
      cpu: 200m
      memory: 100Mi
    limits:
      memory: 500Mi

# Additional resources if we want to add a port for a debugger to connect to.
debug:
  enabled: false
  # Define here any port that you want to expose for debugging purposes
  ports: []
  # By default do not enable this, but by default at least provide a way to
  # dump the $_SERVER variables; this should also be used to inject files into
  # the running deployments for e.g. debugging a production environment.
  php:
    enabled: false
    contents:
      vardump: |-
        <?php
        header("Content-Type: text/plain");
        var_dump($_SERVER);
  annotation: "change-me-to-redeploy"

networkpolicy:
  egress:
    enabled: false

php:
  httpd:
    version: "2.4.38-1-s1"
    port: "8080"
    exporter:
      version: 0.0.4
      requests:
        cpu: 100m
        memory: 50Mi
      limits:
        cpu: 500m
        memory: 200Mi
    requests:
      cpu: 200m
      memory: 600Mi
    limits:
      cpu: 1
      memory: 800Mi
  # PHP version in the production image on which the mediawiki app image is
  # based. Used to identify, e.g., version-specific config volume mount paths.
  version: "8.1"
  fcgi_mode: FCGI_TCP
  exporter:
    version: 0.0.4
    requests:
      cpu: 100m
      memory: 50Mi
    limits:
      cpu: 500m
      memory: 200Mi
  servergroup: main
  auto_prepend_file: "/srv/mediawiki/wmf-config/PhpAutoPrepend.php"
  # Values for local development
  opcache:
    size: 200 # Megabytes. Probably needs a boost in production
    nofiles: "1000" # Number of files. Definitely needs a boost in production
    interned_strings_buffer: "10" # Megabytes. Memory used to store identical strings
  apc:
    size: 400 # Megabytes
  workers: 5 # You need 2 at the very least.
  # CPU requests calculation done by the chart:
  # Minimum 1 whole CPU (enforced by the chart)
  # Multiply the amount of cpu_per_worker (float, unit: cpu, ex: 0.5 is half a CPU per worker)
  # by the number of configured workers + 1 (to take into account the main php-fpm process)
  # The example below results in a cpu request of 3
  cpu_per_worker: 0.5
  # RAM requests calculation done by the chart:
  # Multiply the amount of memory_per_worker by the number of workers (ignoring the main php-fpm process)
  # Add 50% of the opcache size and 50% of the apc size (close to the average real consumption)
  # The example below results in a memory request of 2800Mi
  memory_per_worker: 500 # Megabytes. 500MB is half the memory limit per worker set in mediawiki.
  timeout: "60"
  slowlog_timeout: 0
  display_errors: "Off"
  error_log: "/dev/stderr"
  error_reporting: "30719" #  var_dump(E_ALL & ~E_STRICT);
  pcre_backtrack_limit: "5000000"
  max_execution_time: "210"
  devel_mode: false # If true, enables opcache revalidation and catch_workers_output
# See the dockerfiles for the php-fpm base image to know what can be tweaked.
# Those can be passed via config.public above (if the variable name is all
# uppercase).
# If you want to pass an environment variable to the php-fpm daemon, you can
# use the following dictionary. If you want to make a variable available to php-fpm
# without defining it in the chart (for example, an env variable provided by kubernetes)
# you can add it to the envvars dictionary providing a false/null value.
envvars: {}

mw:
  # The datacenter. To be overridden in deployments.
  datacenter: local
  # Primary datacenter and read-only status
  # Overriden by conftool-data in production
  primary_dc: local
  read_only:
    local: false
  domain_suffix: "local"
  egress:
    database_networks: "10.0.0.0/8"
    etcd_servers: [] # If present, they need to have the form "{ip: <>, port: <>}"
  httpd:
    # disabled by mw-script, mw-videoscaler, mw-cron etc
    enabled: true
    image_tag: latest
    # Add here any apache configuration you might want to test/preload.
    # It will be loaded before all the rest of conf-available and after modules have loaded.
    # See https://github.com/wikimedia/operations-docker-images-production-images/blob/master/images/MediaWiki/httpd/apache2/apache2.conf
    additional_config: false
  localmemcached:
    # Enable to start memcache daemons in the pod, one for each of the
    # ports listed.  These can serve as placeholders for
    # mcrouter to allow for image testing in non-production
    # environments.  If this section is enabled then the mcrouter
    # sections must be disabled.
    enabled: false
    ports: [11212, 11213]
    resources:
      requests:
        cpu: 200m
        memory: 80Mi
      limits:
        cpu: 200m
        memory: 80Mi
  # Uncomment this to override the default value for MW__MCROUTER_SERVER
  # mcrouter_server: 127.0.0.1:11213
  sites:
    - name: wikipedia.local
      priority: 1
      defaults:
        ensure: present
        public_rewrites: true
      vhosts:
        - name: wikipedia.local
          server_aliases:
            - "*.wikipedia.org"
          docroot: "/srv/mediawiki/docroot/wikipedia.org"
          short_urls: true
          wikibase_rewrites: true
          upload_rewrite:
            domain_catchall: wikipedia.org
            rewrite_prefix: wikipedia
          legacy_rewrites: true
          variant_aliases:
            - sr
            - sr-ec
            - sr-el
            - zh
            - zh-hans
            - zh-hant
            - zh-cn
            - zh-hk
            - zh-my
            - zh-mo
            - zh-sg
            - zh-tw
          additional_rewrites:
            late:
              - "# moved wikistats off NFS"
              - "    RewriteRule ^/wikistats(/(.*$)|$) %{ENV:RW_PROTO}://stats.wikimedia.org/$2
                [R=302,L]"
    - name: static
      priority: 2
      content: |+
        <Virtualhost *:8080>
          Servername test
          ServerAlias test.local
          DocumentRoot /srv/mediawiki/docroot/standard-docroot
        </VirtualHost>
  logging:
    # Log in ecs format by default
    format: ecs_rsyslog
    kafka_brokers:
      - host: kafka-host-1
        port: 9001
      - host: kafka-host-2
        port: 6667
    ca_cert_path: /path/to/ca.pem
    rsyslog: false
    debug: false
    allowed_address: 127.0.0.1
    requests:
      cpu: 100m
      memory: 200Mi
    limits:
      cpu: 1
      memory: 300Mi
    udp2log_hostport: somehost:9000
    udp2log_ratelimit_interval: 1
    udp2log_ratelimit_burst: 100
    rsyslog_max_message_size: 64k
  geoip: true
  # If true, this mounts /srv/mediawiki from the wikikube host
  # This feature is only enabled in the mw-experimental service
  experimental:
    enabled: false
  # Feature flags enabled / disabled based on specific traits.
  helpers:
    feature_flags:
      default:
        web: true
        job: false
        cron: false
        mercurius: false
        active_active: true
        dumps: false
        networkpolicy: true
      async: {}
      cli:
        web: false
        job: true
        active_active: false
        networkpolicy: true
      periodic:
        web: false
        job: false # this overrides the value we get from the "cli" trait if it's selected.
        cron: true
        networkpolicy: true
      videoscaler:
        web: false
        deployment: false
        mercurius: true
      dumps:
        cron: false # this overrides the value we get from "periodic" if selected.
        # This might seem counterintuitive, but dumps are a read-only operation
        active_active: true
        dumps: true
        # TODO: add a feature flag for dumps.persistence.enabled too?
  networkpolicy:
    # Override to allow the networkpolicy to apply to different selection of pods
    selectors: ~

common_images:
  rsyslogd: rsyslogd:latest
  mcrouter:
    mcrouter: mcrouter:latest
    exporter: prometheus-mcrouter-exporter:latest
  memcached: memcached:latest
  wmfdebug: wmfdebug:latest
  statsd:
    exporter: prometheus-statsd-exporter:latest

app:
  port: 8080

cache:
  mcrouter:
    port: 11213
    enabled: false
    # Needs to finish after envoy, so it's set to mesh.prestop_sleep + 1
    prestop_sleep: 8
    resources:
      requests:
        cpu: 200m
        memory: 100Mi
      limits:
        cpu: 1
        memory: 200Mi
    route_prefix: local/mw # change this in production based on datacenter
    cross_region_timeout: 250
    cross_cluster_timeout: 100
    probe_timeout: 60000
    timeouts_until_tko: 3
    num_proxies: 5
    zone: local
    pools:
      - name: test-pool
        zone: local
        servers:
          - 10.10.10.10
          - 10.10.10.11
        failover:
          - 10.10.10.12
      - name: remote-pool
        zone: remote
        servers:
          - 10.100.1.2
          - 10.100.1.3
        failover:
          - 10.100.1.4
    routes:
      # Remember - at least one of your zones must match the route_prefix above
      - route: /local/mw
        failover_time: 600
        pool: test-pool
      - route: /local/mw-wan
        pool: test-pool
        failover_time: 600
        replica:
          route: /remote/mw-wan
          pool: remote-pool
    exporter:
      resources:
        requests:
          cpu: 100m
          memory: 50Mi
        limits:
          cpu: 500m
          memory: 200Mi

# ingress configuration. Turned off for any normal deployment
# as this is only to consider for very low traffic instances.
# Allow external traffic to reach this service via a (cluster provided) ingress controller.
# https://wikitech.wikimedia.org/wiki/Kubernetes/Ingress#Configuration_(for_service_owners)
ingress:
  enabled: false
  # By default, enabling ingress will switch the charts services from type NodePort to
  # ClusterIP. While that is fine for new services it may not be desired during transition
  # of existing ones from dedicated LVS to Ingress.
  # By setting keepNodePort to true, the services will stay of type NodePort.
  keepNodePort: false
  # Setting staging to true will use the staging domain to generate the default gateway
  # hosts. It will also ensure that default staging cergen certificates are be trusted.
  staging: false
  # gatewayHosts settings configure the hostnames this service will be reachable on.
  # By default, this will be a list like:
  # - {{ gatewayHosts.default }}.discovery.wmnet
  # - {{ gatewayHosts.default }}.svc.codfw.wmnet
  # - {{ gatewayHosts.default }}.svc.eqiad.wmnet
  #
  # And in case .Values.ingress.staging is true:
  # - {{ gatewayHosts.default }}.k8s-staging.discovery.wmnet
  gatewayHosts:
    # default will expand to {{ .Release.Namespace }} as long as it is an empty string.
    default: ""
    # disableDefaultHosts may be set to true if the service should not be reachable via
    # the gateway hosts generated by default (see above).
    disableDefaultHosts: false
    # extraFQDNs is a list of extra FQDNs this service should be reachable on.
    # It can be used to extend the gateway hosts that are generated by default.
    extraFQDNs: []
  # If you want to attach routes of this release to an existing Gateway, provide the name
  # of that gateway here in the format: <namespace>/<gateway-name>
  # This is useful if you wish to make multiple releases available from the same hostname.
  existingGatewayName: ""
  # routeHosts is a list of FQDNs the httproutes should attach to.
  # If existingGatewayName not set, this list might be empty and will default to the gateway
  # host generated according to how .Values.gatewayHosts.* is configured.
  # If existingGatewayName is set, you need to provide the FQDNs your routes should attach to.
  routeHosts: []
  # HTTPRoute routing rules. By default https://<hosts from above>/ will be routed to
  # the service without modification.
  # Docs: https://istio.io/v1.9/docs/reference/config/networking/virtual-service/#HTTPRoute
  httproutes: []

# This is for maintenance scripts. When mw.helpers.feature_flags.job is true for your deployment,
# the normal MediaWiki Deployment is turned off, and instead a Job runs the provided script.
mwscript:
  command: []
  args: []
  env: {}
  labels: {}
  comment: ""
  tty: false
  stdin: false

mercurius:
  enabled: false
  # TODO Currently we only support a single job - jobs is maintained
  # as a list here as in future we will be adding support for multiple
  # jobs
  jobs: []
  brokers: []
  workers: 10
  # Number of times to retry a failed job
  max_retries: 3
  # First interval for expotential backoff
  retry_interval: 10
  monitor_port: 9100
  # maximum number of times to restart a failing mercurius instance
  backoff_limit: 10
  debug: false
  consumer_properties:
    # avoid processing old jobs on startup
    auto.offset.reset: largest
  # If set, generation is a suffix that will be appended to the "release
  # version" used in both constructing the mercurius job name and defining the
  # release id in config and the release.json control file.
  # This is useful when a helmfile-only update affecting the job template is
  # needed, in the absence of an image update.
  #generation: 0

mwcron:
  enabled: false
  labels: {}
  suspended_jobs: []

dumps:
  enabled: false
  persistence:
    enabled: false
    claim_name: "mw-dumps-shared-pvc"
    mount_path: "/mnt/dumps"
    storage_class: "override_me"
    size: "10Gi"
