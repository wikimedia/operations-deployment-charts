# Default values.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

_vars:
  hadoop_conf_dir: &hadoop_conf_dir /etc/hadoop/conf

docker:
  registry: docker-registry.wikimedia.org
  pull_policy: IfNotPresent
resources:
  replicas: 1

app:
  port: 8080 # Not required

config:
  public:
    "HADOOP_CONF_DIR": *hadoop_conf_dir
    "HIVE_CONF_DIR": *hadoop_conf_dir
  private: {}

  hadoop:
    hdfs:
      dfs.permissions.superusergroup: hadoop
      dfs.datanode.failed.volumes.tolerated: '2'
      dfs.ha.automatic-failover.enabled: 'true'
      dfs.namenode.service.handler.count: '100'
      dfs.nameservices: override_me
      dfs.internal.nameservices: override_me
      dfs.namenode.shared.edits.dir: override_me
      dfs.journalnode.edits.dir: /var/lib/hadoop/journal
      dfs.ha.fencing.methods: shell(/bin/true)
      dfs.namenode.name.dir: file:///var/lib/hadoop/name
      dfs.namenode.handler.count: '127'
      dfs.namenode.quota.init-threads: '16'
      dfs.block.size: '268435456'
      dfs.blocksize: '268435456'
      dfs.datanode.hdfs-blocks-metadata.enabled: 'true'
      dfs.datanode.fsdataset.volume.choosing.policy: org.apache.hadoop.hdfs.server.datanode.fsdataset.AvailableSpaceVolumeChoosingPolicy
      dfs.webhdfs.enabled: 'false'
      dfs.namenode.audit.log.async: 'true'
      dfs.block.access.token.enable: 'true'
      dfs.data.transfer.protection: privacy
      dfs.encrypt.data.transfer: 'true'
      dfs.encrypt.data.transfer.cipher.key.bitlength: '128'
      dfs.encrypt.data.transfer.cipher.suites: AES/CTR/NoPadding
      dfs.http.policy: HTTPS_ONLY
    core:
      fs.defaultFS: override_me
      ha.zookeeper.quorum: override_me
      io.file.buffer.size: '131072'
      hadoop.proxyuser.mapred.hosts: '*'
      hadoop.proxyuser.mapred.groups: '*'
      fs.trash.checkpoint.interval: '1440'
      fs.trash.interval: '43200'
      net.topology.script.file.name: /usr/local/bin/generate_net_topology.sh
      fs.permissions.umask-mode: '027'
      hadoop.http.staticuser.user: yarn
      hadoop.rpc.protection: privacy
      hadoop.security.authentication: kerberos
      hadoop.ssl.enabled.protocols: TLSv1.2
    yarn:
      spark.authenticate: 'true'
      spark.network.crypto.enabled: 'true'
      yarn.acl.enable: 'true'
      yarn.admin.acl: yarn analytics-admins
      yarn.app.mapreduce.am.env: LD_LIBRARY_PATH=/usr/lib/hadoop/lib/native
      yarn.app.mapreduce.am.scheduler.connection.wait.interval-ms: '5000'
      yarn.app.mapreduce.am.staging-dir: /user
      yarn.application.classpath: $HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*,$HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*,$HADOOP_MAPRED_HOME/*,$HADOOP_MAPRED_HOME/lib/*,$HADOOP_YARN_HOME/*,$HADOOP_YARN_HOME/lib/*
      yarn.log-aggregation-enable: 'true'
      yarn.log-aggregation.retain-check-interval-seconds: '86400'
      yarn.log-aggregation.retain-seconds: '5184000'
      yarn.node-labels.enabled: 'true'
      yarn.node-labels.fs-store.root-dir: override_me
      yarn.nodemanager.log-dirs: ''
      yarn.nodemanager.remote-app-log-dir: /var/log/hadoop-yarn/apps
      yarn.nodemanager.log-aggregation.compression-type: gz
      yarn.resourcemanager.am.max-attempts: '6'
      yarn.resourcemanager.cluster-id: override_me
      yarn.resourcemanager.connect.retry-interval.ms: '2000'
      yarn.resourcemanager.ha.automatic-failover.embedded: 'true'
      yarn.resourcemanager.ha.automatic-failover.enabled: 'true'
      yarn.resourcemanager.ha.enabled: 'true'
      yarn.resourcemanager.ha.rm-ids: override_me
      yarn.resourcemanager.max-completed-applications: '5000'
      yarn.resourcemanager.principal: yarn/_HOST@WIKIMEDIA
      yarn.resourcemanager.recovery.enabled: 'true'
      yarn.resourcemanager.scheduler.class: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
      yarn.resourcemanager.scheduler.monitor.enable: 'true'
      yarn.resourcemanager.store.class: org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore
      yarn.resourcemanager.work-preserving-recovery.enabled: 'true'
      yarn.resourcemanager.zk-address: override_me
      yarn.resourcemanager.zk-state-store.parent-path: /yarn-rmstore/analytics-hadoop
      yarn.resourcemanager.zk-timeout-ms: '20000'
      yarn.scheduler.maximum-allocation-mb: '49152'
      yarn.scheduler.maximum-allocation-vcores: '32'
      yarn.scheduler.minimum-allocation-mb: '1'
      yarn.scheduler.minimum-allocation-vcores: '1'
    hive:
      hive.metastore.uris: override_me
      hive.metastore.kerberos.keytab.file: override_me
      hive.metastore.kerberos.principal: override_me
      hive.server2.authentication.kerberos.principal: override_me
      hive.server2.authentication.kerberos.keytab: override_me
      hive.cluster.delegation.token.store.class: org.apache.hadoop.hive.thrift.DBTokenStore
      hive.metastore.sasl.enabled: 'true'
      hive.server2.thrift.sasl.qop: auth-conf
      hive.support.concurrency: 'false'
      hive.metastore.disallow.incompatible.col.type.changes: 'false'
      hive.metastore.execute.setugi: 'true'
      hive.cli.print.current.db: 'true'
      hive.cli.print.header: 'true'
      hive.mapred.mode: strict
      hive.start.cleanup.scratchdir: 'true'
      hive.exec.stagingdir: /tmp/hive-staging
      hive.error.on.empty.partition: 'true'
      hive.exec.parallel: 'true'
      hive.exec.parallel.thread.number: '8'
      hive.stats.autogather: 'false'
      hive.variable.substitute.depth: '10000'
      hive.aux.jars.path: file:///usr/lib/hive-hcatalog/share/hcatalog/hive-hcatalog-core.jar
      hive.default.fileformat: parquet
      parquet.compression: SNAPPY
      hive.server2.builtin.udf.blacklist: xpath,xpath_string,xpath_boolean,xpath_number,xpath_double,xpath_float,xpath_long,xpath_int,xpath_short
      hive.resultset.use.unique.column.names: 'false'
      hive.exec.submit.local.task.via.child: 'false'
      hive.server2.authentication: KERBEROS
      hive.server2.logging.operation.enabled: 'true'
  spark:
    spark:
      spark.yarn.historyServer.address: override_me
      spark.dynamicAllocation.enabled: true
      spark.shuffle.service.enabled: true
      spark.dynamicAllocation.executorIdleTimeout: 60s
      spark.dynamicAllocation.cachedExecutorIdleTimeout: 3600s
      spark.shuffle.io.maxRetries: 10
      spark.shuffle.io.retryWait: 10s
      spark.executorEnv.LD_LIBRARY_PATH: /usr/lib/hadoop/lib/native
      spark.sql.catalogImplementation: hive
      spark.sql.extensions: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
      spark.sql.catalog.spark_catalog: org.apache.iceberg.spark.SparkSessionCatalog
      spark.sql.catalog.spark_catalog.type: hive
      spark.driver.port: 12000
      spark.port.maxRetries: 100
      spark.ui.port: 4040
      spark.driver.blockManager.port: 13000
      spark.sql.files.maxPartitionBytes: '268435456'
      spark.sql.warehouse.dir: hdfs:///user/hive/warehouse
      spark.yarn.archive: hdfs:///user/spark/share/lib/spark-3.1.2-assembly.jar
      spark.driver.defaultJavaOptions: -Djava.net.useSystemProxies=True
      spark.executor.defaultJavaOptions: -Djava.net.useSystemProxies=True
      spark.authenticate: true
      spark.network.crypto.enabled: true
      spark.network.crypto.keyFactoryAlgorithm: PBKDF2WithHmacSHA256
      spark.network.crypto.keyLength: 256
      spark.network.crypto.saslFallback: false
      spark.eventLog.enabled: true
      spark.eventLog.dir: hdfs:///var/log/spark
      spark.eventLog.compress: true
      spark.kubernetes.authenticate.driver.serviceAccountName: spark

monitoring:
  # If enabled is true, monitoring annotations will be added to the deployment.
  enabled: false

networkpolicy:
  egress:
    enabled: false

# Add here the list of kafka-clusters (by name) that the service will need to reach.
kafka:
  allowed_clusters: []

# Optional affinity settings
affinity: {}
#  affinity:
#    nodeAffinity:
#      requiredDuringSchedulingIgnoredDuringExecution:
#        nodeSelectorTerms:
#          - matchExpressions:
#              - key: some-key
#                operator: In
#                values:
#                  - some-value
#  nodeSelector:
#    node.kubernetes.io/some-key: some-value

# The set of external services to allow egress to
# Example:
# kafka:
# - main-codfw
# - main-eqiad
# presto:
# - analytics
#
# See https://wikitech.wikimedia.org/wiki/Kubernetes/Deployment_Charts#Enabling_egress_to_services_external_to_Kubernetes
# for the list of supported services
external_services: {}

# This allows for serviceaccounts in other namespaces to br granted the rights to manage pods
# within this namespace.
orchestrator:
  service_accounts: {}
# orchestrator:
#   service_accounts:
#     airflow-dummy: [airflow]
#     airflow-dev: [airflow-dev]

# Definition of extra IP: hostnames to be injected in /etc/hosts
# Typically, we use this to force the reverse DNS resolution of an an-master host
# IP to its an-masterxxxx.eqiad.wmnet name and to avoid the coredns service ip reverse
# DNS, to validate Kerberos identity.
host_aliases: {}

kerberos:
  keytabs: ~ # Overridden in the private repo.
  servers: ['override_me'] # Overridden in the /etc/helmfile-defaults/general-{{ .Environment.Name }}.yaml file.
  admin: 'override_me' # Overridden in the /etc/helmfile-defaults/general-{{ .Environment.Name }}.yaml file.