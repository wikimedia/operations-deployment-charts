# WMF production main release specific values.
#
# These are kept out of the primary values.yaml just so that it is easier to use
# with local development.
#
# Settings in this file should apply for all WMF production k8s clusters & enviroments.
# cluster/environment/release specific settings belong in env specific values files.
service:
  deployment: production

app:

  config_files:
    app.config.yaml:

      # Configs for the page_content_change enrichment job.
      enrich:
        # MW API requests should go to local envoy service proxy 'mwapi-async'.
        # https://gerrit.wikimedia.org/g/operations/puppet/+/refs/heads/production/hieradata/common/profile/services_proxy/envoy.yaml
        mediawiki_api_endpoint_template: http://localhost:6500/w/api.php
        ssl_ca_bundle_path: /etc/ssl/certs/ca-certificates.crt

      # Configs for eventutilities python stream_manager.
      stream_manager:
        # Production requests to stream_config_uri should
        # be routed via local envoy service proxy 'mwapi-async'.
        http_client_routes:
          "https://meta.wikimedia.org/w/api.php": "http://localhost:6500"

        # Configure sources and sinks.
        # NOTE: Make sure to set kafka options in environment specific values files.
        source:
          stream: mediawiki.page_change.v1:1.3.0
          connector: kafka
          options:
            properties:
              security.protocol: SSL
              ssl.ca.location: /etc/ssl/certs/wmf-ca-certificates.crt
        sink:
          stream: mediawiki.page_content_change.v1:1.3.0
          connector: kafka
          options:
            delivery_guarantee: AT_LEAST_ONCE
            properties:
              security.protocol: SSL
              ssl.ca.location: /etc/ssl/certs/wmf-ca-certificates.crt
              max.request.size: "10485760" # The eventutilities_python p4j wrapper expects a string.

        # By convention we set job_name equal to k8s namespace.
        # Since this naming will contain hypens, set the error_sink
        # stream name explicitly for production deployments.
        error_sink:
          stream: mw_page_content_change_enrich.error:2.1.0
          connector: kafka
          options:
            delivery_guarantee: AT_LEAST_ONCE
            properties:
              security.protocol: SSL
              ssl.ca.location: /etc/ssl/certs/wmf-ca-certificates.crt
              max.request.size: "10485760" # The eventutilities_python p4j wrapper expects a string.
  job:
    # TODO: we might consider setting
    # kubernetes.operator.job.upgrade.last-state.max.allowed.checkpoint.age.
    # to fallback on savepoints if checkpoints are too old.
    # This might require changing checkpoint retention policy.
    upgradeMode: last-state


  flinkConfiguration:
    # Flink HA config shared across clusters.
    # Swift and Zookeeper specific configs (paths), should be defined
    # in each cluster's  helmfile.
    "state.backend.type": filesystem
    "state.checkpoints.num-retained": "10"
    "s3.access-key": mw-event-enrichment:prod
    # We can put this config in values-main.yaml because it uses discovery endpoint,
    # which will be resolved correctly depending on which DC we are deploying to.
    "s3.endpoint": thanos-swift.discovery.wmnet
    "s3.path.style.access": "true"
    # Since we don't have much operational experience yet, fixed-delay seems like a fine default.
    # We might want to re-assess in the future. With this policy, the application will try a number of
    # `attempts` with a `delay` (seconds) between each try.
    "restart-strategy.type": fixed-delay
    # delay * attempts should be higher than the usual downtime we see.
    # Since we don't have any data yet, set this 30 minutes (180 seconds * 10)
    # to err on the side of caution.
    "restart-strategy.fixed-delay.attempts": "10"
    "restart-strategy.fixed-delay.delay": "180"
    # When HA is disabled we need to set an interval in order to trigger checkpointing.
    # TODO: after gaining some operational experience, set this value to something 
    # meaningful. Given the small size of kafka offsets (KBs), 10 seconds seems a reasonable
    # default.
    "execution.checkpointing.interval": "10000" # 10 seconds.
    # Have flink-operator periodic savepoints for handling job restarts and upgrades.
    "kubernetes.operator.periodic.savepoint.interval": 5m
    # Keep the last 24 hours of savepoints.  Savepoint cleanup happens
    # only when the job is running, so if the job is offline e.g. over a weekend,
    # we won't going to lose the latest savepoint.
    "kubernetes.operator.savepoint.history.max.age": 24h
    # Enables the Kubernetes HA service. Recovery metadata will be stored in a ConfigMap.
    "high-availability": KUBERNETES

# Enable egress.  Specific egress policies should either be added in
# environment/k8s cluster specific networkpolicy.egress.dst_nets,
# or automatically configured via discovery.listeners and/or kafka.allowed_clusters,
networkpolicy:
  egress:
    enabled: true

# Enable the service mesh.
mesh:
  enabled: true

# Enable mwapi-async envoy service proxy.
# This will forward requests to https://localhost:6500 to mw-api-int.discovery.wmnet.
discovery:
  listeners:
    - mw-api-int-async
