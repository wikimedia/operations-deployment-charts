# NOTE: values-codfw.yaml is configured to be deployed in wikikube-codfw k8s.
#
# - reads codfw prefixed topic from Kafka main-codfw,
# - writes to codfw prefixed topic Kafka jumbo-eqiad
# - Stores Flink Checkpoints in thanos swift in codfw (via discovery endpoint)
# - TODO: Stores Flink HA state in Zookeeper main-codfw.
#   https://phabricator.wikimedia.org/T331283

app:
  taskManager:
    # NOTE: taskManager.replicas takes precedence over job.parellism.
    # Input mediawiki.page_change topic has only 1 Kafka topic-partitions (eqiad or codfw).
    # Increasing the parallelism (replicas) can still help process things faster, as
    # there are more tasks running that can process the messages.
    # The app keys messages by (wiki_id, page_id), so we can be sure that parallelizing
    # still produces messages in the proper order, per page.
    replicas: 2
    resource:
      cpu: 2
      # When backfilling, a single TM maxed out at around 2.7GB. Reserve 3G.
      memory: 3000m

  config_files:
    app.config.yaml:

      # Configs for eventutilities python stream_manager.
      stream_manager:
        # Configure sources and sinks.
        source:
          options:
            bootstrap_servers: kafka-main2006.codfw.wmnet:9093,kafka-main2007.codfw.wmnet:9093,kafka-main2008.codfw.wmnet:9093,kafka-main2009.codfw.wmnet:9093,kafka-main2010.codfw.wmnet:9093
            # We run in 'active/active single compute' Multi DC mode, so this
            # app in eqiad should only process the eqiad prefixed topic of the
            # mediawiki.page_change.v1 stream.
            topics: [codfw.mediawiki.page_change.v1]
            # Kafka consumer group naming follows convention: <job_name>__<k8s_cluster_name>
            consumer_group: mw-page-content-change-enrich.wikikube-codfw.000

        sink:
          options:
            bootstrap_servers: kafka-jumbo1010.eqiad.wmnet:9093,kafka-jumbo1011.eqiad.wmnet:9093,kafka-jumbo1012.eqiad.wmnet:9093,kafka-jumbo1013.eqiad.wmnet:9093,kafka-jumbo1014.eqiad.wmnet:9093,kafka-jumbo1015.eqiad.wmnet:9093,kafka-jumbo1016.eqiad.wmnet:9093,kafka-jumbo1017.eqiad.wmnet:9093,kafka-jumbo1018.eqiad.wmnet:9093
            kafka_topic_prefix: codfw.

        error_sink:
          options:
            bootstrap_servers: kafka-jumbo1010.eqiad.wmnet:9093,kafka-jumbo1011.eqiad.wmnet:9093,kafka-jumbo1012.eqiad.wmnet:9093,kafka-jumbo1013.eqiad.wmnet:9093,kafka-jumbo1014.eqiad.wmnet:9093,kafka-jumbo1015.eqiad.wmnet:9093,kafka-jumbo1016.eqiad.wmnet:9093,kafka-jumbo1017.eqiad.wmnet:9093,kafka-jumbo1018.eqiad.wmnet:9093
            kafka_topic_prefix: codfw.

  flinkConfiguration:
    "high-availability.storageDir": s3://mw-page-content-change-enrich.wikikube-codfw/flink/high-availability
    "state.checkpoints.dir": s3://mw-page-content-change-enrich.wikikube-codfw/flink/checkpoints # needed for upgradeMode: savepoint
    "state.savepoints.dir": s3://mw-page-content-change-enrich.wikikube-codfw/flink/savepoints # needed for upgradeMode: savepoint

external_services:
  kafka:
    # Read page change events from main
    - main-codfw
    # Write page content change events to jumbo
    - jumbo-eqiad

networkpolicy:
  egress:
    dst_nets:
      # If we want to use thanos-swift.discovery.wmnet, our app should be DC
      # agnostic.
      # See https://phabricator.wikimedia.org/T346877
      # thanos-swift cluster in codfw for checkpoints
      - cidr: 10.2.1.54/32   # thanos-swift.svc.codfw.wmnet
        ports:
          - port: 443
            protocol: tcp
      # thanos-swift cluster in eqiad for checkpoints
      - cidr: 10.2.2.54/32   # thanos-swift.svc.eqiad.wmnet
        ports:
          - port: 443
            protocol: tcp
