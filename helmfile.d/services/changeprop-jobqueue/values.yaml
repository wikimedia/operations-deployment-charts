main_app:
  version: 2025-06-27-104102-production
  port: 7200

  log_level: error

  redis:
    host: localhost
    port: 6379

  liveness_probe:
    tcpSocket:
      port: 7200

  jobqueue:
    enabled: true
    kafka:
      producer:
        # The default value is 5ms, and we want Changeprop to batch
        # more messages rather than keep sending small ones.
        # T338357
        linger.ms: 20
    jobrunner_uri: https://mw-jobrunner.discovery.wmnet:4448/rpc/RunSingleJob.php

    partitioners: true

    # jobs we don't want to process at all
    # The videotranscode jobs have been moved to use mw-videoscaler and mercurius
    excluded_jobs: ["webVideoTranscode", "webVideoTranscodePrioritized"]

    # All the jobs listed below get their own rule, which transfers to
    # their own processing unit - each type of job listed explicitly is processed
    # by a separate worker in change-prop.
    high_traffic_jobs_config:
      ThumbnailRender:
        enabled: true
        concurrency: 10
      categoryMembershipChange:
        enabled: true
        concurrency: 200
      # CNDPurge is quite low-volume, but it uses delayed execution,
      # so avoid putting it together with other low-volume jobs so that it doesn't
      # block execution for others.
      cdnPurge:
        enabled: true
        concurrency: 40
      ORESFetchScoreJob:
        enabled: true
        concurrency: 30
      # RecordLinks is normally low-volume, but could have big spikes
      # when maintenance scripts are run. Elevated concurrency
      RecordLintJob:
        enabled: true
        concurrency: 50
        consumer_batch_size: 10
      wikibase-addUsagesForPage:
        enabled: true
        concurrency: 20
      constraintsRunCheck:
        enabled: true
        concurrency: 30
      fetchGoogleCloudVisionAnnotations:
        enabled: true
        concurrency: 10
        # All the jobs of this kind are delayed exactly 48 hours, so we don't want
        # the reenqueue feature to kick in.
        reenqueue_delay: 259200
      notificationGetStartedJob:
        enabled: true
        concurrency: 10
        # The jobs have a variable delay (several hours, up to 48 hours),
        # set the reenqueue delay to 30 minutes to ensure variable delays
        # are supported.
        reenqueue_delay: 1800
      notificationKeepGoingJob:
        enabled: true
        concurrency: 10
        # All the jobs of this kind are delayed exactly 48 hours, avoid reenqueueing them
        # by setting the reenqueue delay to 72 hours
        reenqueue_delay: 259200
      newcomerTasksCacheRefreshJob:
        enabled: true
        concurrency: 10
        # All the jobs of this kind are delayed exactly 144 hours (6 days), avoid reenqueueing them
        # by setting the reenqueue delay to 7 days
        reenqueue_delay: 604800
      refreshUserImpactJob:
        enabled: true
        concurrency: 10
      processMediaModeration:
        # unclear as to whether this job is in use
        enabled: true
        # The job calls out to external PhotoDNA service, that has 5 req/s limit.
        # The job takes 0.5s on average, so we would end up making 3.5 req/s on average.
        # In case some of the jobs get rate limited, they will be retried.
        concurrency: 7
      LocalGlobalUserPageCacheUpdateJob:
        # This job is prone to large spikes, so having it on the low_traffic_jobs queue
        # blocks other jobs.
        enabled: true
        concurrency: 25
      # Translation jobs tend to be low traffic but are being delayed when other
      # low traffic jobs have a large spike. It is being moved to its own queue to
      # improve editing experience for users T267520
      UpdateTranslatablePageJob:
        enabled: true
        concurrency: 3
      RenderTranslationPageJob:
        enabled: true
        concurrency: 3
      DispatchChanges:
        enabled: true
        concurrency: 15
      EntityChangeNotification:
        enabled: true
        concurrency: 29
      wikibase-InjectRCRecords:
        enabled: true
        concurrency: 7
      parsoidCachePrewarm:
        enabled: true
        concurrency: 70

    # Some jobs require partitioning according to MariaDB shards.
    partitioned_jobs_config:
      refreshLinks:
        enabled: true
        # Partition jobs by mediawiki database cluster (s1, s2, etc.)
        partitioner_kind: mediawiki_database
        # This is the concurrency for the partitioner
        # itself, it's does not actually touch Mediawiki, only re-enqueues the
        # jobs according to proper partitions
        partitioner_concurrency: 200
        partition:
          # This is the concurrency of the individual partitions, so overall concurrency
          # is 8 * 30 = 240
          concurrency: 30
          # Abandon jobs which root job is more than 1 week long
          root_claim_ttl: 604800
      htmlCacheUpdate:
        enabled: true
        # Partition jobs by mediawiki database cluster (s1, s2, etc.)
        partitioner_kind: mediawiki_database
        partitioner_concurrency: 50
        partition:
          # This is the concurrency of the individual partitions, so overall concurrency
          # is 8 * 4 = 32
          # The load of htmlCacheUpdate is uneven across partitions, so we are using a bit
          # higher overall concurrency then needed.
          concurrency: 4
          # Abandon jobs which root job is more than 1 week long
          root_claim_ttl: 604800

    # Similar to the high_traffic_jobs_config, all jobs listed here get their
    # own rule, and thus a dedicated consumer.
    # While the high_traffic_jobs_config exists in part to isolate high-volume
    # jobs that could otherwise slow down processing for other jobs if left on
    # the shared low_traffic_jobs config, this works the opposite way: it
    # isolates jobs known to be latency sensitive into their own rules.
    latency_sensitive_jobs_config:
      # T379035 - AssembleUploadChunks, PublishStashedFile, and UploadFromUrl,
      # are considered latency sensitive, as high backlog time presents a poor
      # user experience for async uploads.
      AssembleUploadChunks:
        enabled: true
        concurrency: 10
      PublishStashedFile:
        enabled: true
        concurrency: 10
      UploadFromUrl:
        enabled: true
        concurrency: 10

    # All the jobs not explicitly specified in the config are combined into the
    # `low_traffic_jobs` rule, so they share a worker. The low_traffic_concurrency
    # is shared between all the jobs other then the exceptions listed above.
    #
    # Most of the topics are empty most of the time, so a lot of slots are just waiting
    # for the `consume` method to timeout and do nothing.
    # So a significantly higher concurrency is needed to account for that.
    low_traffic_jobs:
      enabled: true
      concurrency: 50

monitoring:
  enabled: true

nutcracker:
  version: 0.0.4


external_services:
  kafka: [main-eqiad, main-codfw]
  redis-6379: [misc]

networkpolicy:
  egress:
    enabled: true
    dst_nets:
      - cidr: 10.2.2.26/32 # jobrunner.svc.eqiad.wmnet
        ports:
          - protocol: tcp
            port: 443
      - cidr: 10.2.1.26/32 # jobrunner.svc.codfw.wmnet
        ports:
          - protocol: tcp
            port: 443
      - cidr: 10.2.2.5/32 # videoscaler.svc.eqiad.wmnet
        ports:
          - protocol: tcp
            port: 443
      - cidr: 10.2.1.5/32 # videoscaler.svc.codfw.wmnet
        ports:
          - protocol: tcp
            port: 443
      - cidr: 10.2.2.90/32 # mw-jobrunner.svc.eqiad.wmnet
        ports:
          - protocol: tcp
            port: 4448
      - cidr: 10.2.1.90/32 # mw-jobrunner.svc.codfw.wmnet
        ports:
          - protocol: tcp
            port: 4448

logging:
  samples:
    debug/request: "0.00005"

metrics:
  name: cpjobqueue

app:
  port: 7200
