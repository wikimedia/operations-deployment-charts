main_app:
  version: 2023-07-28-103633-production
  port: 7200

  log_level: error

  redis:
    host: localhost
    port: 6379

  liveness_probe:
    tcpSocket:
      port: 7200

  jobqueue:
    jobrunner_uri: https://jobrunner.discovery.wmnet/rpc/RunSingleJob.php
    videoscaler_uri: https://videoscaler.discovery.wmnet/rpc/RunSingleJob.php

    partitioners: true

    # All the jobs listed below get their own rule, which transfers to
    # their own processing unit - each type of job listed explicitly is processed
    # by a separate worker in change-prop.
    high_traffic_jobs_config:
      ThumbnailRender:
        enabled: true
        concurrency: 3
      categoryMembershipChange:
        enabled: true
        concurrency: 200
      # CNDPurge is quite low-volume, but it uses delayed execution,
      # so avoid putting it together with other low-volume jobs so that it doesn't
      # block execution for others.
      cdnPurge:
        enabled: true
        concurrency: 40
      ORESFetchScoreJob:
        enabled: true
        concurrency: 30
      # RecordLinks is normally low-volume, but could have big spikes
      # when maintenance scripts are run. Elevated concurrency
      RecordLintJob:
        enabled: true
        concurrency: 100
        consumer_batch_size: 10
      wikibase-addUsagesForPage:
        enabled: true
        concurrency: 20
      constraintsRunCheck:
        enabled: true
        concurrency: 30
      fetchGoogleCloudVisionAnnotations:
        enabled: true
        concurrency: 10
        # All the jobs of this kind are delayed exactly 48 hours, so we don't want
        # the reenqueue feature to kick in.
        reenqueue_delay: 259200
      notificationGetStartedJob:
        enabled: true
        concurrency: 10
        # All the jobs of this kind are delayed exactly 48 hours, avoid reenqueueing them
        # by setting the reenqueue delay to 72 hours
        reenqueue_delay: 259200
      notificationKeepGoingJob:
        enabled: true
        concurrency: 10
        # All the jobs of this kind are delayed exactly 48 hours, avoid reenqueueing them
        # by setting the reenqueue delay to 72 hours
        reenqueue_delay: 259200
      newcomerTasksCacheRefreshJob:
        enabled: true
        concurrency: 10
        # All the jobs of this kind are delayed exactly 144 hours (6 days), avoid reenqueueing them
        # by setting the reenqueue delay to 7 days
        reenqueue_delay: 604800
      refreshUserImpactJob:
        enabled: true
        concurrency: 3
      # For cirrus search jobs the retries are built into the job itself,
      # so disable the retries by change-prop. We need special rules for cirrus
      # jobs because they need special configuration.
      cirrusSearchCheckerJob:
        enabled: true
        disable_delayed_execution: true #T198462
        retry_limit: 0
        concurrency: 30
      cirrusSearchDeleteArchive:
        enabled: true
        retry_limit: 0
        concurrency: 5
      cirrusSearchDeletePages:
        enabled: true
        retry_limit: 0
        concurrency: 5
      cirrusSearchIncomingLinkCount:
        enabled: true
        retry_limit: 0
        concurrency: 15
      cirrusSearchLinksUpdate:
        enabled: true
        retry_limit: 0
        concurrency: 300
      cirrusSearchLinksUpdatePrioritized:
        enabled: true
        retry_limit: 0
        concurrency: 150
      cirrusSearchOtherIndex:
        enabled: true
        retry_limit: 0
        concurrency: 5
      processMediaModeration:
        enabled: true
        # The job calls out to external PhotoDNA service, that has 5 req/s limit.
        # The job takes 0.5s on average, so we would end up making 3.5 req/s on average.
        # In case some of the jobs get rate limited, they will be retried.
        concurrency: 7
      LocalGlobalUserPageCacheUpdateJob:
        # This job is prone to large spikes, so having it on the low_traffic_jobs queue
        # blocks other jobs.
        enabled: true
        concurrency: 25
      # Translation jobs tend to be low traffic but are being delayed when other
      # low traffic jobs have a large spike. It is being moved to its own queue to
      # improve editing experience for users T267520
      UpdateTranslatablePageJob:
        enabled: true
        concurrency: 3
      RenderTranslationPageJob:
        enabled: true
        concurrency: 3
      DispatchChanges:
        enabled: true
        concurrency: 15
      EntityChangeNotification:
        enabled: true
        concurrency: 29
      wikibase-InjectRCRecords:
        enabled: true
        concurrency: 7
      parsoidCachePrewarm:
        enabled: true
        concurrency: 150

    # Videoscaler jobs point to a different LVS, so they need special treatment
    # as well - thus special rules.
    videoscaler_jobs_config:
      webVideoTranscode:
        enabled: true
        timeout: 86400000
        concurrency: 10
      webVideoTranscodePrioritized:
        enabled: true
        concurrency: 5
        timeout: 86400000

    # Some jobs require partitioning according to MariaDB shards.
    partitioned_jobs_config:
      refreshLinks:
        enabled: true
        # Partition jobs by mediawiki database cluster (s1, s2, etc.)
        partitioner_kind: mediawiki_database
        # This is the concurrency for the partitioner
        # itself, it's does not actually touch Mediawiki, only re-enqueues the
        # jobs according to proper partitions
        partitioner_concurrency: 200
        partition:
          # This is the concurrency of the individual partitions, so overall concurrency
          # is 8 * 30 = 240
          concurrency: 30
          # Abandon jobs which root job is more than 1 week long
          root_claim_ttl: 604800
      htmlCacheUpdate:
        enabled: true
        # Partition jobs by mediawiki database cluster (s1, s2, etc.)
        partitioner_kind: mediawiki_database
        partitioner_concurrency: 50
        partition:
          # This is the concurrency of the individual partitions, so overall concurrency
          # is 8 * 4 = 32
          # The load of htmlCacheUpdate is uneven across partitions, so we are using a bit
          # higher overall concurrency then needed.
          concurrency: 4
          # Abandon jobs which root job is more than 1 week long
          root_claim_ttl: 604800
      cirrusSearchElasticaWrite:
        enabled: true
        partitioner_kind: cirrussearch_cluster
        partitioner_concurrency: 50
        partition:
          # This is the concurrency of the individual partitions, so overall concurrency
          # is 150 * 3 = 450
          concurrency: 150
          reenqueue_delay: 3600
          retry_limit: 0

    # All the jobs not explicitly specified in the config are combined into the
    # `low_traffic_jobs` rule, so they share a worker. The low_traffic_concurrency
    # is shared between all the jobs other then the exceptions listed above.
    #
    # Most of the topics are empty most of the time, so a lot of slots are just waiting
    # for the `consume` method to timeout and do nothing.
    # So a significantly higher concurrency is needed to account for that.
    low_traffic_jobs:
      enabled: true
      concurrency: 50

monitoring:
  enabled: true

nutcracker:
  version: 0.0.4

networkpolicy:
  egress:
    enabled: true
    dst_nets:
      - cidr: 10.192.0.17/32 # kafka-main2001
        ports:
          - protocol: tcp
            port: 9092
          - protocol: tcp
            port: 9093
      - cidr: 10.192.16.8/32 # kafka-main2002
        ports:
          - protocol: tcp
            port: 9092
          - protocol: tcp
            port: 9093
      - cidr: 10.192.32.136/32 # kafka-main2003
        ports:
          - protocol: tcp
            port: 9092
          - protocol: tcp
            port: 9093
      - cidr: 2620:0:860:101:10:192:0:17/128 # kafka-main2001
        ports:
          - protocol: tcp
            port: 9092
          - protocol: tcp
            port: 9093
      - cidr: 2620:0:860:102:10:192:16:8/128 # kafka-main2002
        ports:
          - protocol: tcp
            port: 9092
          - protocol: tcp
            port: 9093
      - cidr: 2620:0:860:103:10:192:32:136/128 # kafka-main2003
        ports:
          - protocol: tcp
            port: 9092
          - protocol: tcp
            port: 9093
      - cidr: 10.192.48.38/32 # kafka-main2004
        ports:
          - protocol: tcp
            port: 9092
          - protocol: tcp
            port: 9093
      - cidr: 2620:0:860:104:10:192:48:38/128 # kafka-main2004
        ports:
          - protocol: tcp
            port: 9092
          - protocol: tcp
            port: 9093
      - cidr: 10.192.48.46/32 # kafka-main2005
        ports:
          - protocol: tcp
            port: 9092
          - protocol: tcp
            port: 9093
      - cidr: 2620:0:860:104:10:192:48:46/128 # kafka-main2005
        ports:
          - protocol: tcp
            port: 9092
          - protocol: tcp
            port: 9093
      - cidr: 10.64.0.200/32 # kafka-main1001
        ports:
          - protocol: tcp
            port: 9092
          - protocol: tcp
            port: 9093
      - cidr: 10.64.16.37/32 # kafka-main1002
        ports:
          - protocol: tcp
            port: 9092
          - protocol: tcp
            port: 9093
      - cidr: 10.64.32.90/32 # kafka-main1003
        ports:
          - protocol: tcp
            port: 9092
          - protocol: tcp
            port: 9093
      - cidr: 2620:0:861:101:10:64:0:200/128 # kafka-main1001
        ports:
          - protocol: tcp
            port: 9092
          - protocol: tcp
            port: 9093
      - cidr: 2620:0:861:102:10:64:16:37/128 # kafka-main1002
        ports:
          - protocol: tcp
            port: 9092
          - protocol: tcp
            port: 9093
      - cidr: 2620:0:861:103:10:64:32:90/128 # kafka-main1003
        ports:
          - protocol: tcp
            port: 9092
          - protocol: tcp
            port: 9093
      - cidr: 10.64.48.30/32 #kafka-main1004
        ports:
          - protocol: tcp
            port: 9092
          - protocol: tcp
            port: 9093
      - cidr: 2620:0:861:107:10:64:48:30/128 #kafka-main1004
        ports:
          - protocol: tcp
            port: 9092
          - protocol: tcp
            port: 9093
      - cidr: 10.64.48.31/32 #kafka-main1005
        ports:
          - protocol: tcp
            port: 9092
          - protocol: tcp
            port: 9093
      - cidr: 2620:0:861:107:10:64:48:31/128 #kafka-main1005
        ports:
          - protocol: tcp
            port: 9092
          - protocol: tcp
            port: 9093
      - cidr: 10.2.2.26/32 # jobrunner.svc.eqiad.wmnet
        ports:
          - protocol: tcp
            port: 443
      - cidr: 10.2.1.26/32 # jobrunner.svc.codfw.wmnet
        ports:
          - protocol: tcp
            port: 443
      - cidr: 10.2.2.5/32 # videoscaler.svc.eqiad.wmnet
        ports:
          - protocol: tcp
            port: 443
      - cidr: 10.2.1.5/32 # videoscaler.svc.codfw.wmnet
        ports:
          - protocol: tcp
            port: 443
      - cidr: 10.192.0.198/32 # rdb2007
        ports:
          - protocol: tcp
            port: 6379
      - cidr: 10.192.16.213/32 # rdb2008
        ports:
          - protocol: tcp
            port: 6379
      - cidr: 2620:0:860:101:10:192:0:198/128 # rdb2007
        ports:
          - protocol: tcp
            port: 6379
      - cidr: 2620:0:860:102:10:192:16:213/128 # rdb2008
        ports:
          - protocol: tcp
            port: 6379
      - cidr: 10.192.32.8/32 # rdb2009
        ports:
          - protocol: tcp
            port: 6379
      - cidr: 10.192.48.6/32 # rdb2010
        ports:
          - protocol: tcp
            port: 6379
      - cidr: 2620:0:860:103:10:192:32:8/128 # rdb2009
        ports:
          - protocol: tcp
            port: 6379
      - cidr: 2620:0:860:104:10:192:48:6/128 # rdb2010
        ports:
          - protocol: tcp
            port: 6379
      - cidr: 10.64.0.36/32 # rdb1011
        ports:
          - protocol: tcp
            port: 6379
      - cidr: 10.64.16.76/32 # rdb1009
        ports:
          - protocol: tcp
            port: 6379

logging:
  samples:
    debug/request: "0.00005"

metrics:
  name: cpjobqueue

app:
  port: 7200
