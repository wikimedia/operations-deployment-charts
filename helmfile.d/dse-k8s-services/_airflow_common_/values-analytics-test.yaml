worker:
  config:
    hadoop:
      hdfs:
        dfs.client.failover.proxy.provider.analytics-test-hadoop: org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
        dfs.ha.namenodes.analytics-test-hadoop: an-test-master1001-eqiad-wmnet,an-test-master1002-eqiad-wmnet
        dfs.internal.nameservices: analytics-test-hadoop
        dfs.namenode.http-address.analytics-test-hadoop.an-test-master1001-eqiad-wmnet: an-test-master1001.eqiad.wmnet:50070
        dfs.namenode.http-address.analytics-test-hadoop.an-test-master1002-eqiad-wmnet: an-test-master1002.eqiad.wmnet:50070
        dfs.namenode.rpc-address.analytics-test-hadoop.an-test-master1001-eqiad-wmnet: an-test-master1001.eqiad.wmnet:8020
        dfs.namenode.rpc-address.analytics-test-hadoop.an-test-master1002-eqiad-wmnet: an-test-master1002.eqiad.wmnet:8020
        dfs.namenode.servicerpc-address.analytics-test-hadoop.an-test-master1001-eqiad-wmnet: an-test-master1001.eqiad.wmnet:8040
        dfs.namenode.servicerpc-address.analytics-test-hadoop.an-test-master1002-eqiad-wmnet: an-test-master1002.eqiad.wmnet:8040
        dfs.nameservices: analytics-test-hadoop
      core:
        fs.defaultFS: hdfs://analytics-test-hadoop/
      yarn:
        yarn.node-labels.fs-store.root-dir: hdfs://analytics-test-hadoop/user/yarn/node-labels
        yarn.resourcemanager.cluster-id: analytics-test-hadoop
        yarn.resourcemanager.ha.rm-ids: an-test-master1001-eqiad-wmnet,an-test-master1002-eqiad-wmnet
        yarn.resourcemanager.hostname.an-test-master1001-eqiad-wmnet: an-test-master1001.eqiad.wmnet
        yarn.resourcemanager.hostname.an-test-master1002-eqiad-wmnet: an-test-master1002.eqiad.wmnet
        yarn.resourcemanager.webapp.address.an-test-master1001-eqiad-wmnet: an-test-master1001.eqiad.wmnet:8088
        yarn.resourcemanager.webapp.address.an-test-master1002-eqiad-wmnet: an-test-master1002.eqiad.wmnet:8088
      hive:
        hive.metastore.kerberos.principal: hive/analytics-test-hive.eqiad.wmnet@WIKIMEDIA
        hive.metastore.uris: thrift://analytics-test-hive.eqiad.wmnet:9083
        hive.server2.authentication.kerberos.principal: hive/analytics-test-hive.eqiad.wmnet@WIKIMEDIA

config:
  connections:
    analytics-test-hive:
      conn_type: hive_metastore
      host: analytics-test-hive.eqiad.wmnet
      port: 9083
      extra_dejson:
        auth_mechanism: GSSAPI
    datahub_gms:
      conn_type: datahub-rest
      host: http://datahub-gms-staging.datahub-next.svc:8080
    datahub_kafka_test:
      conn_type: datahub_kafka
      host: kafka-test-eqiad.external-services.svc.cluster.local
      port: 9092
      extra_dejson:
        connection:
          schema_registry_url: https://datahub-gms-next.discovery.wmnet:30443/schema-registry/api/
          schema_registry_config:
            ssl.ca.location: /etc/ssl/certs/ca-certificates.crt

external_services:
  task-pod:
    # When connecting to the analytics-test-hadoop cluster, the task pods need access
    # to the master (to submit jobs), the workers (to fetch data) as well as Hive, to
    # sense data partitions.
    hadoop-master: [analytics-test]
    hadoop-worker: [analytics-test]
    hive: [analytics-test]
    druid: [analytics-test]
  hadoop-shell:
    # Give access to hadoop subsystems to the hadoop shell
    hadoop-master: [analytics-test]
    hadoop-worker: [analytics-test]

# We hardcode this hostname / ip mapping to allow Hadoop to perform a reverse DNS
# resolution of the IPs and to get these hostnames, instead of the coreDNS reverse
# service IP PTR entries, to make it validate the Kerberos service name.
# See https://phabricator.wikimedia.org/T377602#10295542
host_aliases:
  an-test-master1001.eqiad.wmnet: 10.64.5.39
  an-test-master1002.eqiad.wmnet: 10.64.36.112

hadoop_shell:
  enabled: true
