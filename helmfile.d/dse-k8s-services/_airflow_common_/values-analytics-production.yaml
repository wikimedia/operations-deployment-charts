worker:
  config:
    hadoop:
      hdfs:
        dfs.client.failover.proxy.provider.analytics-hadoop: org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
        dfs.ha.namenodes.analytics-hadoop: an-master1003-eqiad-wmnet,an-master1004-eqiad-wmnet
        dfs.internal.nameservices: analytics-hadoop
        dfs.namenode.http-address.analytics-hadoop.an-master1003-eqiad-wmnet: an-master1003.eqiad.wmnet:50070
        dfs.namenode.http-address.analytics-hadoop.an-master1004-eqiad-wmnet: an-master1004.eqiad.wmnet:50070
        dfs.namenode.rpc-address.analytics-hadoop.an-master1003-eqiad-wmnet: an-master1003.eqiad.wmnet:8020
        dfs.namenode.rpc-address.analytics-hadoop.an-master1004-eqiad-wmnet: an-master1004.eqiad.wmnet:8020
        dfs.namenode.servicerpc-address.analytics-hadoop.an-master1003-eqiad-wmnet: an-master1003.eqiad.wmnet:8040
        dfs.namenode.servicerpc-address.analytics-hadoop.an-master1004-eqiad-wmnet: an-master1004.eqiad.wmnet:8040
        dfs.nameservices: analytics-hadoop
        dfs.namenode.shared.edits.dir: qjournal://an-worker1078.eqiad.wmnet:8485;an-worker1080.eqiad.wmnet:8485;an-worker1090.eqiad.wmnet:8485;an-worker1142.eqiad.wmnet:8485;analytics1072.eqiad.wmnet:8485/analytics-hadoop
      core:
        fs.defaultFS: hdfs://analytics-hadoop/
      yarn:
        yarn.node-labels.fs-store.root-dir: hdfs://analytics-hadoop/user/yarn/node-labels
        yarn.resourcemanager.cluster-id: analytics-hadoop
        yarn.resourcemanager.ha.rm-ids: an-master1003-eqiad-wmnet,an-master1004-eqiad-wmnet
        yarn.resourcemanager.hostname.an-master1003-eqiad-wmnet: an-master1003.eqiad.wmnet
        yarn.resourcemanager.hostname.an-master1004-eqiad-wmnet: an-master1004.eqiad.wmnet
        yarn.resourcemanager.webapp.address.an-master1003-eqiad-wmnet: an-master1003.eqiad.wmnet:8088
        yarn.resourcemanager.webapp.address.an-master1004-eqiad-wmnet: an-master1004.eqiad.wmnet:8088
      hive:
        hive.metastore.kerberos.principal: hive/analytics-hive.eqiad.wmnet@WIKIMEDIA
        hive.metastore.uris: thrift://analytics-hive.eqiad.wmnet:9083
        hive.server2.authentication.kerberos.principal: hive/analytics-hive.eqiad.wmnet@WIKIMEDIA

config:
  connections:
    analytics-hive:
      conn_type: hive_metastore
      host: analytics-hive.eqiad.wmnet
      port: 9083
      extra_dejson:
        authMechanism: GSSAPI
    datahub_gms:
      conn_type: datahub-rest
      host: http://datahub-gms-production.datahub.svc:8080
    datahub_kafka_jumbo:
      conn_type: datahub_kafka
      host: kafka-jumbo-eqiad.external-services.svc.cluster.local
      port: 9092
      extra_dejson:
        connection:
          schema_registry_url: https://datahub-gms.discovery.wmnet:30443/schema-registry/api/
          schema_registry_config:
            ssl.ca.location: /etc/ssl/certs/ca-certificates.crt

external_services:
  task-pod:
    # When connecting to the analytics-hadoop cluster, the task pods need access
    # to the master (to submit jobs), the workers (to fetch data) as well as Hive, to
    # sense data partitions.
    hive: [analytics]
    hadoop-master: [analytics]
    hadoop-worker: [analytics]
    druid: [analytics]
  hadoop-shell:
    # Give access to hadoop subsystems to the hadoop shell
    hadoop-master: [analytics]
    hadoop-worker: [analytics]
# We hardcode this hostname / ip mapping to allow Hadoop to perform a reverse DNS
# resolution of the IPs and to get these hostnames, instead of the coreDNS reverse
# service IP PTR entries, to make it validate the Kerberos service name.
# See https://phabricator.wikimedia.org/T377602#10295542
host_aliases:
  an-master1003.eqiad.wmnet: 10.64.36.15
  an-master1004.eqiad.wmnet: 10.64.53.14
