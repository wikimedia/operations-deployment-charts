opensearchCluster:
  enabled: true
#  bootstrap:
#    Configure settings for the bootstrap pod
  general:
    image: docker-registry.wikimedia.org/repos/data-engineering/opensearch:2025-09-02-211140-2ef1c90115e12fc0a475a1b15c358c3657a5348b
    imagePullPolicy: Never
    httpPort: "9200"
    version: 2.7.0
    drainDataNodes: true
    setVMMaxMapCount: false
# The following securityContext values are required by policy on all WMF k8s clusters, ref T362978
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
          - ALL
      readOnlyRootFilesystem: false
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    podSecurityContext:
      fsGroup: 999
      runAsUser: 999

#        securityContext:
#           Specify container security context for OSD pods
#        podSecurityContext:
#           Specify pod security context for OSD pods
    resources:
      requests:
        memory: "1Gi"
        cpu: "500m"
      limits:
        memory: "1Gi"
        cpu: "500m"
# The chart version we are currently using in production (2.7.0) cannot set the
# WMF-required securityContext for the initHelper container.
# Luckily, this is OK because we don't run the initHelper at WMF.
# We toggle it off via the envvar "SKIP_INIT_CONTAINER," which is found in
# charts/opensearch-operator/values.yaml
  initHelper:
    imagePullSecrets: []
    # - registryKeySecretName
    imagePullPolicy: IfNotPresent
    image: docker-registry.wikimedia.org/trixie
    # version: '20250817'
    resources: {}
    # requests:
    #   memory: "1Gi"
    #   cpu: "500m"
    # limits:
    #   memory: "1Gi"
    #   cpu: "500m"
# The following securityContext values are required by policy on all WMF k8s clusters, ref T362978
    securityContext:
      capabilities:
        drop:
          - ALL
    podSecurityContext:
      fsGroup: 999
      runAsUser: 999
  nodePools:
    - component: masters
      diskSize: "30Gi"
      # Needed to avoid OOMKills due to JVM cgroup detection bug, see T405361
      jvm: -Xmx1024M -Xms1024M
      persistence:
        pvc:
          storageClass: ceph-rbd-ssd
          accessModes:
            - ReadWriteOnce
      replicas: 3
      roles:
        - "master"
        - "data"
      resources:
        requests:
          memory: "2Gi"
          cpu: "500m"
        limits:
          memory: "2Gi"
          cpu: "500m"
    # These annotations enable/configure metrics scrapes
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9200"
        prometheus.io/path: "/_prometheus/metrics"
    # prevent 2 masters from being scheduled on the same k8s worker
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  opster.io/opensearch-cluster: opensearch-cluster
                  opster.io/opensearch-nodepool: masters
              topologyKey: kubernetes.io/hostname
  security:
    # https://github.com/opensearch-project/opensearch-k8s-operator/blob/v2.7.0/docs/userguide/main.md#securityconfig
    config:  # Everything related to the securityconfig
      securityConfigSecret:
        # Name of the Secret containing the securityconfig files (roles, role mappings, users, config)
        name:  securityconfig-secret
      adminSecret:
        # Name of the Secret containing the admin client certificate, used by the security plugin pod
        # to connect to the opensearch service and authenticate via mTLS
        name:  opensearch-wmf-admin
      adminCredentialsSecret:
        # Name of the Secret containing username/password for admin access
        name: config-secret

app:
  port: 9200
  protocol: TCP
