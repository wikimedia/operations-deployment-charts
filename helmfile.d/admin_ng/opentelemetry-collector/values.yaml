mode: daemonset

rollout:
  rollingUpdate:
    maxUnavailable: 9

# The Kubernetes Attributes Processor automatically discovers Kubernetes pods, extracts their metadata,
# and adds the extracted metadata to spans, metrics, and logs as resource attributes.
# https://opentelemetry.io/docs/kubernetes/collector/components/#kubernetes-attributes-processor
# https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/k8sattributesprocessor/README.md
presets:
  kubernetesAttributes:
    enabled: true

securityContext:
  allowPrivilegeEscalation: false
  capabilities:
     drop:
     - ALL
  runAsNonRoot: true
  seccompProfile:
    type: RuntimeDefault

config:
  # Disable all receivers except OTLP
  receivers:
    jaeger: null
    prometheus: null
    zipkin: null
  exporters:
    otlp:
      # Don't forget to update the egress rules below upon changing this
      endpoint: jaeger-collector-grpc.svc.eqiad.wmnet:30443
      tls:
        ca_file: /etc/ssl/certs/wmf-ca-certificates.crt
  processors:
    # Override the default settings of the k8sattributes processor -- we extract fewer
    # fields, and don't extract any that require a LIST+WATCH on replicasets (T366094)
    k8sattributes:
      extract:
        metadata:
          - "k8s.namespace.name"
          - "k8s.node.name"
          - "k8s.pod.name"
          - "k8s.pod.uid"
          - "k8s.pod.start_time"

    # Rewrite service.name to something meaningful, as our Envoys don't
    # currently provide this.  https://phabricator.wikimedia.org/T363407
    # Do this using the transformprocessor:
    # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/transformprocessor
    #
    # In this step, because of https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/32080#issuecomment-2112490125
    # we only mutate the per-span `service.name` attribute, not the resource-level one.
    # This is because the resource-level container likely has children spans that need to be split up first.
    # Later we will use groupbyattrs to aggregate these into the Resource's service.name correctly.
    transform/service_from_upstream_cluster_or_nodeid:
      error_mode: ignore
      trace_statements:
        - context: span
          statements:
            # Begin by duplicating any resource service.name into the span-level attributes.
            - set(attributes["service.name"], resource.attributes["service.name"])
            # Remove any "LOCAL_" prefix from the upstream cluster name...
            - replace_pattern(attributes["upstream_cluster.name"], "^LOCAL_", "")
            # ...and potentially use the rest as the service name, if we don't have a good one already.
            - set(attributes["service.name"], attributes["upstream_cluster.name"])
                where ((attributes["service.name"] == nil)
                       or (attributes["service.name"] == "")
                       or (attributes["service.name"] == "OTLPResourceNoServiceName"))
                and (attributes["upstream_cluster.name"] != "local_service")
            # Failing that, use the k8s-namespace-derived service name.
            - set(attributes["service.name"], resource.attributes["k8s.namespace.name"])
                where ((attributes["service.name"] == nil)
                       or (attributes["service.name"] == "")
                       or (attributes["service.name"] == "OTLPResourceNoServiceName"))
                and (resource.attributes["k8s.namespace.name"] != nil) and (resource.attributes["k8s.namespace.name"] != "")
    # Re-group spans by their per-span service.name attribute we computed above.
    # https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/processor/groupbyattrsprocessor/README.md
    groupbyattrs/service_name:
      keys:
        - service.name
    filter/healthchecks:
      error_mode: ignore
      traces:
        span:
          # Filter out spans that match any of these conditions.
          - IsMatch(attributes["http.url"], "/wiki/Special:BlankPage$$")
          - IsMatch(attributes["http.url"], "/healthz$$")

    # Sometimes traces have PII or other sensitive information in them.  Scrub it out.
    transform/scrub:
      error_mode: ignore
      trace_statements:
        - context: span
          # For sessionstore, scrub out the actual session ID from the URL.  It's PII.
          conditions:
            - resource.attributes["service.name"] == "sessionstore"
          statements:
            - replace_pattern(attributes["http.url"], "/sessions/v1/([^%]+)%3[Aa]([^%]+)%3[Aa].+", "/sessions/v1/$$1%3A$$2%3A{token}")
            # Note that when using OTTL within the collector's configuration file, $ must be escaped
            # to $$ to bypass environment variable substitution logic.
        # ðŸ‘‹ Hello service owner and/or SRE friends!
        # If you have sensitive data in your spans, you can scrub it out here.
        # Make sure to condition on your service name.
        # Remember that the `conditions:` block is a list which is all OR'd together.
        # Define your additional trace-data-scrubbing rules hereðŸ‘‡, beginning with `- context: span`

    # The only span name we get from Envoy is 'ingress'. Let's try to make it more useful.
    transform/operation_name:
      error_mode: ignore
      trace_statements:
        - context: span
          conditions:  # list of conditions is all OR'd together
            # If we have a URL, but not a useful operation name ...
            - attributes["http.url"] != nil and attributes["operation.name"] == nil
            - attributes["http.url"] != nil and attributes["operation.name"] == "ingress"
          statements:
            # ... let's generate one.  Combining the method and URL is a good start.
            #
            # If the URL begins with http://localhost, it's an internal request made via the mesh.
            # Strip out that part.
            # Otherwise, this is likely a wiki user request, or the first ingress for something user-facing.
            # In that case, leave the hostname, it's meaningful.
            #
            # TODO: Stop using regexes for URLs.  https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/32433
            - set(cache["url"], attributes["http.url"])  # cache[] is a free scratch space for OTTL transforms
            - replace_pattern(cache["url"], "^http://localhost[^/]*(/.*)", "$$1")
            - set(name, Concat([attributes["http.method"], cache["url"]], " "))
  service:
    pipelines:
      metrics: ~
      logs: ~
      traces:
        receivers:
          - otlp
        processors:
          - k8sattributes
          - transform/service_from_upstream_cluster_or_nodeid
          - groupbyattrs/service_name
          - filter/healthchecks
          - transform/scrub
          - transform/operation_name
          - memory_limiter
          - batch
        exporters:
          - otlp

resources:
  limits:
    cpu: 256m
    memory: 512Mi

# Use the WMF Docker registry, not Docker Hub, and specify our most recent build (overriding the
# appVersion from Chart.yaml).
image:
  repository: docker-registry.discovery.wmnet/otelcol
  tag: 0.102.0-1

command:
  # The chart adds a leading slash (because the default is just "otelcol-contrib" with the binary
  # installed at the root.)
  name: usr/bin/otelcol-contrib

# Disable all ports except OTLP
ports:
  otlp:
    # Disable the hostPort; we'll use a NodePort service instead.
    hostPort: null
  otlp-http:
    # Disable the hostPort; we'll use a NodePort service instead.
    hostPort: null
  jaeger-compact:
    enabled: false
  jaeger-thrift:
    enabled: false
  jaeger-grpc:
    enabled: false
  zipkin:
    enabled: false

service:
  enabled: true
  type: ClusterIP
  internalTrafficPolicy: Local

networkPolicy:
  enabled: true
  egressRules:
    - to:
        - ipBlock:
            cidr: 10.2.2.78/32 # jaeger-collector-grpc.svc.eqiad.wmnet
      ports:
        - port: 30443
          protocol: TCP
    # TODO: Here, in order to support the k8sattributes processor, we hardcode the IPs of the
    # k8s API endpoints.  This is not ideal, but it's the best we can do until we have a better
    # way -- probably either creating a wrapper chart that also creates a Calico NetworkPolicy
    # object that allows the k8s API endpoints, or, creating an otelcol chart of our own.
    # https://phabricator.wikimedia.org/T365855
    # kubectl get endpoints -n default kubernetes -oyaml | yq -c '.subsets[].addresses[] | {"ipBlock": {"cidr": (.ip + "/32")}}' - | jq -s | yq -y
    - to:
        # eqiad k8s API endpoint IPs
        - ipBlock:
            cidr: 10.64.0.117/32
        - ipBlock:
            cidr: 10.64.32.116/32
        - ipBlock:
            cidr: 10.64.16.93/32
        - ipBlock:
            cidr: 10.64.48.45/32
        - ipBlock:
            cidr: 10.64.32.37/32
        # codfw k8s API endpoint IPs
        - ipBlock:
            cidr: 10.192.0.56/32
        - ipBlock:
            cidr: 10.192.15.6/32
        - ipBlock:
            cidr: 10.192.16.48/32
        - ipBlock:
            cidr: 10.192.32.105/32
        - ipBlock:
            cidr: 10.192.5.10/32
      ports:
        - port: 6443
          protocol: TCP

  extraIngressRules:
    - ports:
      - port: 8888
        protocol: TCP

podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "8888"
