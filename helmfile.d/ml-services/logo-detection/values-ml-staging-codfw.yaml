inference:
  predictor:
    config:
      # These settings are applied at the pod level,
      # that includes all containers not explicitly defined
      # in the isvc (like the istio-{validation,proxy}).
      # The knative-serving ones seem to need
      # an extra level of settings in the knative's control-plane
      # due to how the various pods/revisions are handled
      # (dynamically etc..).
      # More info https://phabricator.wikimedia.org/T369493
      securityContext:
        seccompProfile:
          type: RuntimeDefault

inference_services:
  logo-detection:
    predictor:
      config:
        minReplicas: 1
        maxReplicas: 1
      image: "machinelearning-liftwing-inference-services-logo-detection"
      image_version: "2025-05-23-112400-publish"
      custom_env:
        - name: MODEL_NAME
          value: "logo-detection"
        - name: STORAGE_URI
          value: "s3://wmf-ml-models/logo-detection/20240417132942/"
      container:
        resources:
          limits:
            cpu: "2"
            memory: 2Gi
          requests:
            cpu: "2"
            memory: 2Gi
