inference_services:

  revertrisk-wikidata:
    predictor:
      image: "machinelearning-liftwing-inference-services-revertrisk-wikidata"
      image_version: "2026-01-12-112314-publish"
      custom_env:
        - name: MODEL_NAME
          value: "revertrisk-wikidata"
        - name: STORAGE_URI
          value: "s3://wmf-ml-models/revertrisk/wikidata/20251104121312/"
        - name: FORCE_HTTP
          value: "True"
        - name: WORKERS
          value: "8"
      container:
        resources:
          limits:
            cpu: "8"
            memory: 16Gi
          requests:
            cpu: "8"
            memory: 16Gi

  articlequality:
    predictor:
      image: "machinelearning-liftwing-inference-services-articlequality"
      image_version: "2025-10-16-103324-publish"
      custom_env:
        - name: MODEL_NAME
          value: "articlequality"
        - name: STORAGE_URI
          value: "s3://wmf-ml-models/articlequality/language-agnostic/20250425125943/"
        - name: FORCE_HTTP
          value: "True"
      container:
        resources:
          limits:
            memory: 1Gi
          requests:
            memory: 1Gi

  reference-need:
    annotations:
      autoscaling.knative.dev/target: "3"
    predictor:
      config:
        minReplicas: 1
        maxReplicas: 1
      image: "machinelearning-liftwing-inference-services-reference-quality"
      image_version: "2025-03-19-145037-publish"
      custom_env:
        - name: STORAGE_URI
          value: "s3://wmf-ml-models/reference-quality/20250127142109/"
        - name: FORCE_HTTP
          value: "True"
        - name: MODEL_TO_DEPLOY
          value: "reference-need"
        - name: BATCH_SIZE
          value: "16"
          # We set number of threads for each worker model to (num_cpus/2)-1 to leave CPU capacity to the main event loop
        - name: NUM_THREADS
          value: "7"
        - name: NUM_OF_WORKERS
          value: "2"
      container:
        resources:
          limits:
            cpu: "16"
            memory: 4Gi
          requests:
            cpu: "16"
            memory: 4Gi

  reference-risk:
    annotations:
      autoscaling.knative.dev/target: "3"
    predictor:
      config:
        minReplicas: 1
        maxReplicas: 8
      image: "machinelearning-liftwing-inference-services-reference-quality"
      image_version: "2025-05-23-112449-publish"
      custom_env:
        - name: STORAGE_URI
          value: "s3://wmf-ml-models/reference-quality/20250127142109/"
        - name: FORCE_HTTP
          value: "True"
        - name: MODEL_TO_DEPLOY
          value: "reference-risk"
      container:
        resources:
          limits:
            cpu: "4"
            memory: 3Gi
          requests:
            cpu: "4"
            memory: 3Gi


  article-country:
    predictor:
      image: "machinelearning-liftwing-inference-services-article-country"
      image_version: "2025-05-23-112448-publish"
      custom_env:
        - name: MODEL_NAME
          value: "article-country"
        - name: STORAGE_URI
          value: "s3://wmf-ml-models/article-country/20240901015102/"
        - name: FORCE_HTTP
          value: "True"
      container:
        resources:
          limits:
            cpu: "2"
            memory: 2Gi
          requests:
            cpu: "2"
            memory: 2Gi

  edit-check:
    predictor:
      config:
        maxReplicas: 1
        batcher:
          maxBatchSize: 32
          maxLatency: 100
      image: "machinelearning-liftwing-inference-services-edit-check"
      image_version: "2025-06-25-142517-publish"
      custom_env:
        - name: MODEL_NAME
          value: "edit-check-staging"
        - name: STORAGE_URI
          value: "s3://wmf-ml-models/edit-check/peacock/"
        - name: MODEL_VERSION
          value: "v1"
        - name: USE_METADATA
          value: "true"
      container:
        resources:
          limits:
            cpu: "4"
            memory: 8Gi
          requests:
            cpu: "4"
            memory: 8Gi

  embeddings:
    predictor:
      config:
        maxReplicas: 1
      image: "machinelearning-liftwing-inference-services-embeddings"
      image_version: "2026-01-06-082802-publish"
      custom_env:
        - name: MODEL_NAME
          value: "qwen3-embedding"
        - name: STORAGE_URI
          value: "s3://wmf-ml-models/qwen3-embedding-0.6b/20251218133542/"
        - name: MODEL_VERSION
          value: "Qwen3-Embedding-0.6B"
        - name: LOCAL_FILES_ONLY
          value: "True"
        - name: DTYPE
          value: "float16"
        - name: ATTN_IMPLEMENTATION
          value: "flash_attention_2"
        - name: MAX_LENGTH
          value: "500"
      container:
        resources:
          limits:
            cpu: "2"
            memory: 8Gi
            amd.com/gpu: "1"
          requests:
            cpu: "2"
            memory: 8Gi
            amd.com/gpu: "1"

external_services_app_label_selector: app-wmf
external_services:
  cassandra:
  - ml-cache-a-eqiad
  - ml-cache-a-codfw
  - cassandra-dev-a-codfw
  - cassandra-dev-b-codfw
  - analytics-query-service-storage-a-codfw
  - analytics-query-service-storage-b-codfw
  - analytics-query-service-storage-a-eqiad
  - analytics-query-service-storage-b-eqiad
