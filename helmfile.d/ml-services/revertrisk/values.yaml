docker:
  registry: docker-registry.discovery.wmnet/wikimedia
  imagePullPolicy: IfNotPresent

networkpolicy:
  egress:
    enabled: true
    # These endpoints should be reachable by Istio proxy sidecars.
    dst_nets:
      - cidr: 10.2.1.54/32 # thanos-swift.svc.codfw.wmnet
        ports:
        - port: 443
          protocol: tcp
      - cidr: 10.2.2.54/32 # thanos-swift.svc.eqiad.wmnet
        ports:
        - port: 443
          protocol: tcp
      - cidr: 10.2.1.22/32 # api-ro.svc.codfw.wmnet
        ports:
        - port: 443
          protocol: tcp
      - cidr: 10.2.2.22/32 # api-ro.svc.eqiad.wmnet
        ports:
        - port: 443
          protocol: tcp
      - cidr: 10.2.1.81/32 # mw-api-int-ro.svc.codfw.wmnet
        ports:
        - port: 4446
          protocol: tcp
      - cidr: 10.2.2.81/32 # mw-api-int-ro.svc.eqiad.wmnet
        ports:
        - port: 4446
          protocol: tcp
      - cidr: 10.2.1.45/32 # eventgate-main.svc.codfw.wmnet
        ports:
        - port: 4492
          protocol: tcp
      - cidr: 10.2.2.45/32 # eventgate-main.svc.eqiad.wmnet
        ports:
        - port: 4492
          protocol: tcp

monitoring:
  enabled: true

inference:
  annotations:
    sidecar.istio.io/inject: "true"
    autoscaling.knative.dev/metric: "rps"
    prometheus.kserve.io/scrape: "true"
    prometheus.kserve.io/port: "8080"
    prometheus.kserve.io/path: "/metrics"

inference_services:
  revertrisk-language-agnostic:
    annotations:
      autoscaling.knative.dev/target: "15"
    predictor:
      config:
        minReplicas: 5
        maxReplicas: 15
      image: "machinelearning-liftwing-inference-services-revertrisk"
      image_version: "2026-01-08-091023-publish"
      custom_env:
        - name: MODEL_NAME
          value: "revertrisk-language-agnostic"
        - name: STORAGE_URI
          value: "s3://wmf-ml-models/revertrisk/language-agnostic/20231117132654/"
        - name: WIKI_URL
          value: "http://mw-api-int-ro.discovery.wmnet:4680"
        - name: EVENTGATE_URL
          value: "http://eventgate-main.discovery.wmnet:4480/v1/events"
        - name: EVENTGATE_STREAM
          value: "mediawiki.page_revert_risk_prediction_change.v1"
  revertrisk-multilingual:
    annotations:
      autoscaling.knative.dev/target: "3"
    predictor:
      config:
        minReplicas: 3
        maxReplicas: 15
      image: "machinelearning-liftwing-inference-services-revertrisk-multilingual"
      image_version: "2026-01-15-110714-publish"
      custom_env:
        - name: MODEL_NAME
          value: "revertrisk-multilingual"
        - name: STORAGE_URI
          value: "s3://wmf-ml-models/revertrisk/multilingual/20230810110019/"
        - name: WIKI_URL
          value: "http://mw-api-int-ro.discovery.wmnet:4680"
      container:
        resources:
          limits:
            cpu: "4"
            memory: 6Gi
          requests:
            cpu: "4"
            memory: 6Gi
  revertrisk-language-agnostic-pre-save:
    annotations:
      autoscaling.knative.dev/target: "15"
    predictor:
      config:
        minReplicas: 1
        maxReplicas: 3
      image: "machinelearning-liftwing-inference-services-revertrisk"
      image_version: "2026-01-08-091023-publish"
      custom_env:
        - name: MODEL_NAME
          value: "revertrisk-language-agnostic"
        - name: STORAGE_URI
          value: "s3://wmf-ml-models/revertrisk/language-agnostic/20231117132654/"
        - name: FORCE_HTTP
          value: "true"
        - name: ALLOW_REVISION_JSON_INPUT
          value: "true"
  revertrisk-multilingual-pre-save:
    annotations:
      autoscaling.knative.dev/target: "3"
    predictor:
      config:
        minReplicas: 1
        maxReplicas: 3
      image: "machinelearning-liftwing-inference-services-revertrisk-multilingual"
      image_version: "2026-01-15-110714-publish"
      custom_env:
        - name: MODEL_NAME
          value: "revertrisk-multilingual"
        - name: STORAGE_URI
          value: "s3://wmf-ml-models/revertrisk/multilingual/20230810110019/"
        - name: FORCE_HTTP
          value: "true"
        - name: ALLOW_REVISION_JSON_INPUT
          value: "true"
      container:
        resources:
          limits:
            cpu: "4"
            memory: 6Gi
          requests:
            cpu: "4"
            memory: 6Gi

  revertrisk-wikidata:
    annotations:
      autoscaling.knative.dev/target: "3"
    predictor:
      config:
        minReplicas: 1
        maxReplicas: 1
      image: "machinelearning-liftwing-inference-services-revertrisk-wikidata"
      image_version: "2026-02-16-101949-publish"
      custom_env:
        - name: MODEL_NAME
          value: "revertrisk-wikidata"
        - name: STORAGE_URI
          value: "s3://wmf-ml-models/revertrisk/wikidata/20251104121312/"
        - name: FORCE_HTTP
          value: "True"
        # For a single GPU, we must use a single worker to manage it.
        - name: WORKERS
          value: "1"
      container:
        resources:
          limits:
            cpu: "8"
            memory: 16Gi
            amd.com/gpu: "1"
          requests:
            cpu: "8"
            memory: 16Gi
            amd.com/gpu: "1"
